{"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751246462475,"user_tz":420,"elapsed":118,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"}},"outputId":"80a64081-3a93-47a3-9287-5630f14d4458","id":"QuhI-kIxbHmC"},"source":["!streamlit run SpyderStream.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: streamlit: command not found\n"]}]},{"cell_type":"code","metadata":{"id":"kixdyZQBbJOo"},"source":["!streamlit run SpyderStream.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"DvN9f8KLSyI5"},"outputs":[],"source":["# @title\n","# ============================================\n","# ðŸ”§ Install Libraries\n","# ============================================\n","!pip install pandas matplotlib openpyxl fpdf2 openai google-generativeai\n","\n","# ============================================\n","# ðŸ“¦ Import Libraries\n","# ============================================\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from fpdf import FPDF\n","from google.colab import files\n","import openai\n","from google.colab import userdata\n","import os\n","import google.generativeai as genai # Import google.generativeai\n","import numpy as np # Import numpy\n","\n","\n","# ============================================\n","# ðŸ”‘ API Keys\n","# ============================================\n","# Get the API keys from Colab Secrets\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY') # Get Gemini API key\n","\n","# Initialize OpenAI client (if still needed for other parts of the script)\n","client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","\n","# Configure Gemini API\n","genai.configure(api_key=GOOGLE_API_KEY)\n","# Initialize the Gemini model\n","gemini_model = genai.GenerativeModel('gemini-pro') # Or another suitable Gemini model\n","\n","\n","# ============================================\n","# ðŸ“ Upload the SpyderTrades CSV File\n","# ============================================\n","print(\"Upload the SpyderTrades CSV file\")\n","uploaded = files.upload()\n","\n","# Process the first uploaded file and save with a consistent name\n","if uploaded:\n","    uploaded_filename = list(uploaded.keys())[0]\n","    consistent_filename = 'uploaded_trades.' + uploaded_filename.split('.')[-1] # Use original extension\n","\n","    # Save with the consistent filename, overwriting if it exists\n","    with open(consistent_filename, 'wb') as f:\n","        f.write(uploaded[uploaded_filename])\n","\n","    print(f\"âœ… File '{uploaded_filename}' uploaded and saved as '{consistent_filename}'\")\n","\n","    # Read the file into a DataFrame\n","    if consistent_filename.endswith('.csv'):\n","        df = pd.read_csv(consistent_filename)\n","    elif consistent_filename.endswith(('.xls', '.xlsx')):\n","        df = pd.read_excel(consistent_filename)\n","    else:\n","        print(f\"Unsupported file type: {consistent_filename}\")\n","        df = pd.DataFrame() # Create empty DataFrame if file type is unsupported\n","\n","else:\n","    print(\"No file uploaded.\")\n","    df = pd.DataFrame() # Create empty DataFrame if no file is uploaded\n","\n","\n","# Clean column names by stripping leading/trailing spaces\n","df.columns = df.columns.str.strip()\n","\n","# print(\"\\nOriginal DataFrame Head:\")\n","# display(df.head())\n","print(\"âœ… File processing initiated\")\n","\n","# ============================================\n","# âš™ï¸ Process Data\n","def parse_premium(val):\n","        try:\n","            return float(val.replace('$', '').replace(',', '').replace('k', 'e3').replace('m', 'e6'))\n","        except:\n","            return 0\n","\n","df['PremiumValue'] = df['Premium'].apply(parse_premium)\n","print(\"âœ… Premium column parsed\")\n","\n","# Parse sentiment from trade spread\n","def get_sentiment(spread):\n","    if pd.isna(spread):\n","        return 'Neutral'\n","    spread = str(spread).lower()\n","    if 'above ask' in spread:\n","        return 'Aggressive Bullish'\n","    if 'ask' in spread:\n","        return 'Bullish'\n","    if 'bidish' in spread:\n","        return 'Bearish'\n","    if 'at bid' in spread:\n","        return 'Aggressive Bearish'\n","    return 'Neutral'\n","\n","df['Sentiment'] = df['Trade Spread'].apply(get_sentiment)\n","print(\"âœ… Sentiment assigned\")\n","\n","# Stealth indicator\n","df['Stealth'] = df['Alerts'].apply(lambda x: 'âœ… High Stealth' if pd.notna(x) else 'âŒ None')\n","\n","# Trade Type\n","df['Trade Type'] = df['Flags'].fillna('Unknown')\n","\n","# Strike/Expiry label\n","df['StrikeExpiry'] = df['Strike'].astype(str) + ' ' + df['Call/Put'].astype(str) + ' â€“ ' + df['Expiration Date'].astype(str)\n","\n","# Rename the 'Symbol' column to 'Ticker' for consistency and merging later\n","df = df.rename(columns={'Symbol': 'Ticker'})\n","\n","\n","# print(\"\\nDataFrame Head after initial processing:\")\n","# display(df.head())\n","\n","# ============================================\n","# ðŸ“Š Summary Table\n","# ============================================\n","summary = df.groupby('Ticker').agg({\n","    'PremiumValue': ['sum', 'max', 'count']\n","}).reset_index()\n","\n","summary.columns = ['Ticker', 'Total Premium', 'Max Premium', 'Trade Count']\n","\n","# Pull info for max premium trade\n","max_trades = df.loc[df.groupby('Ticker')['PremiumValue'].idxmax()][\n","    ['Ticker', 'Trade Type', 'StrikeExpiry', 'Sentiment', 'Stealth'] # Use Ticker here\n","]\n","\n","summary = summary.merge(max_trades, on='Ticker', how='left') # Merge on Ticker\n","\n","# Dummy Market Cap tags (adjust as needed)\n","summary['Market Cap'] = 'Mid Cap'\n","summary.loc[summary['Ticker'].isin(['RKLB', 'SOUN', 'ACHR', 'NVTS']), 'Market Cap'] = 'Small Cap'\n","\n","print(\"âœ… Data summarized\")\n","# print(\"\\nSummary DataFrame Head:\")\n","# display(summary.head())\n","\n","\n","# Merge the 'Market Cap' column from the summary DataFrame into the main df DataFrame\n","df = df.merge(summary[['Ticker', 'Market Cap']], on='Ticker', how='left')\n","# print(\"\\nDataFrame Head after merging Market Cap:\")\n","# display(df.head())\n","\n","\n","# ============================================\n","# âš™ï¸ Create Strategy Columns\n","# ============================================\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","print(\"âœ… Strategy columns created\")\n","# print(\"\\nDataFrame Head with Strategy Columns:\")\n","# display(df[['Ticker', 'Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())\n","\n","\n","# ============================================\n","# ðŸ“Š Define Unusual Option Activity Criteria and Implement Identification\n","# ============================================\n","# 1. Define a threshold for \"Large Premium\" (using the 95th percentile of 'PremiumValue')\n","large_premium_threshold = df['PremiumValue'].quantile(0.95)\n","print(f\"\\nLarge Premium Threshold (95th percentile): ${large_premium_threshold:,.2f}\")\n","\n","# 2. Create the 'IsUnusual' column based on the three criteria\n","df['IsUnusual'] = (\n","    (df['PremiumValue'] > large_premium_threshold) | # Criterion 1: Large Premium\n","    (df['Vol > OI']) | # Criterion 2: Volume > Open Interest (already calculated)\n","    ((df['Sweep'] | df['Repeater']) & df['Above Ask']) # Criterion 3: Aggressive Execution with Strategy Flags\n",")\n","print(f\"Number of trades flagged as unusual: {df['IsUnusual'].sum()}\")\n","# print(\"\\nDataFrame Head with IsUnusual Column:\")\n","# display(df[['Ticker', 'PremiumValue', 'Vol > OI', 'Sweep', 'Repeater', 'Above Ask', 'IsUnusual']].head())\n","\n","\n","# ============================================\n","# ðŸ“Š Define and Implement Scoring System\n","# ============================================\n","def calculate_score(row):\n","    \"\"\"Calculates a trade score based on sentiment, stealth, and unusual activity.\"\"\"\n","    score = 0\n","\n","    # Score based on Sentiment (example weighting)\n","    if row['Sentiment'] == 'Aggressive Bullish' or row['Sentiment'] == 'Aggressive Bearish':\n","        score += 5\n","    elif row['Sentiment'] == 'Bullish' or row['Sentiment'] == 'Bearish':\n","        score += 3\n","    else: # Neutral\n","        score += 1\n","\n","    # Score based on Stealth\n","    if row['Stealth'] == 'âœ… High Stealth':\n","        score += 4\n","    else: # âŒ None\n","        score += 1\n","\n","    # Score based on Unusual Activity\n","    if row['IsUnusual']:\n","        score += 5\n","    else:\n","        score += 1 # Even non-unusual trades get a base score\n","\n","    return score\n","\n","# Apply the function to create the 'Score' column\n","df['Score'] = df.apply(calculate_score, axis=1)\n","\n","print(\"âœ… Trade scores calculated\")\n","# print(\"\\nDataFrame Head with Score Column:\")\n","# display(df[['Ticker', 'Sentiment', 'Stealth', 'IsUnusual', 'Score']].head())\n","\n","\n","# ============================================\n","# ðŸ”¥ Filter Top Trades (Using New Scoring)\n","# ============================================\n","# Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False]).copy() # Use .copy() to avoid SettingWithCopyWarning\n","\n","# Select the top 3 overall trades\n","top3_overall_scored = df_sorted.head(3).copy() # Use .copy()\n","\n","# Filter for Small Cap trades and select the top 3\n","small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap'].copy() # Use .copy()\n","top3_small_cap_scored = small_cap_df_sorted.head(3).copy() # Use .copy()\n","\n","# Merge relevant columns from the summary DataFrame into top3_overall_scored\n","top3_overall_scored = top3_overall_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Merge relevant columns from the summary DataFrame into top3_small_cap_scored\n","top3_small_cap_scored = top3_small_cap_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","print(\"âœ… Top 3 overall and small cap trades filtered (using new scoring)\")\n","# print(\"\\nTop 3 Overall Scored Trades:\")\n","# display(top3_overall_scored[['Ticker', 'Score', 'PremiumValue', 'Sentiment_summary', 'Stealth_summary', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count']])\n","# print(\"\\nTop 3 Small Cap Scored Trades:\")\n","# display(top3_small_cap_scored[['Ticker', 'Score', 'PremiumValue', 'Sentiment_summary', 'Stealth_summary', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count']])\n","\n","\n","# ============================================\n","# ðŸ§  AI Summary Function (Using OpenAI)\n","# ============================================\n","def ai_summary(ticker, premium, trade_type, strike_expiry, sentiment, stealth):\n","    prompt = f\"\"\"\n","Write a short professional summary of the following options trade:\n","\n","Ticker: {ticker}\n","Trade Type: {trade_type}\n","Premium: ${premium:,.0f}\n","Strike/Expiry: {strike_expiry}\n","Sentiment: {sentiment}\n","Stealth Indicator: {stealth}\n","\n","Summarize the intent behind this flow in the style of an institutional options flow report.\n","\"\"\"\n","    try:\n","        # Use the OpenAI model to generate content\n","        response = client.chat.completions.create(\n","          model=\"gpt-4\",  # You can choose a different OpenAI model if preferred\n","          messages=[\n","            {\"role\": \"system\", \"content\": \"You are a financial analyst specializing in options trading.\"},\n","            {\"role\": \"user\", \"content\": prompt}\n","          ]\n","        )\n","        return response.choices[0].message.content\n","    except Exception as e:\n","        return f\"Error generating summary with OpenAI: {e}\"\n","\n","\n","# ============================================\n","# ðŸ“ OMENReport Template With AI Summaries (TXT Format)\n","# ============================================\n","# Define a function to format the scored trade data and AI summaries for TXT\n","def format_scored_omen_template_txt(df, title, strategy_columns):\n","    \"\"\"Formats scored trade data and AI summaries into a string for the TXT report.\"\"\"\n","    report = f\"\\nðŸš€ OMENReport â€“ {title}\\n\\n\"\n","    report += f\"ðŸ“… Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\"\n","\n","    for _, row in df.iterrows():\n","        report += \"==========================================\\n\"\n","        report += f\"ðŸ”¶ Ticker: {row['Ticker']}\\n\"\n","        report += f\"- Market Cap: {row['Market Cap']}\\n\"\n","        report += f\"- Score: {row['Score']}\\n\" # Include the score\n","        report += f\"- Trade Type: {row['Trade Type']}\\n\"\n","        report += f\"- Strike/Expiry: {row['StrikeExpiry']}\\n\"\n","        report += f\"- Premium Size (Max Trade): ${row['Max Premium']:,.0f}\\n\" # Use Max Premium from summary merge\n","        report += f\"- Total Premium: ${row['Total Premium']:,.0f}\\n\" # Use Total Premium from summary merge\n","        report += f\"- Trade Count: {int(row['Trade Count'])}\\n\" # Use Trade Count from summary merge\n","        report += f\"- Sentiment: {row['Sentiment_summary']}\\n\" # Use Sentiment from summary merge\n","        report += f\"- Stealth Indicator: {row['Stealth_summary']}\\n\" # Use Stealth from summary merge\n","        report += \"\\n\"\n","\n","        # Add strategy criteria details\n","        report += \"Strategy Criteria Met:\\n\"\n","        for col in strategy_columns:\n","            # Ensure the column exists and is boolean before checking\n","            if col in row and isinstance(row[col], bool):\n","                 status = \"âœ… Yes\" if row[col] else \"âŒ No\"\n","                 report += f\"  - {col}: {status}\\n\"\n","        report += \"\\n\"\n","\n","\n","        report += \"ðŸ§  AI Summary:\\n\"\n","        # Generate AI summary using the OpenAI-powered function\n","        try:\n","            ai_text = ai_summary(\n","                ticker=row['Ticker'],\n","                premium=row['Max Premium'],\n","                trade_type=row['Trade Type'],\n","                strike_expiry=row['StrikeExpiry'],\n","                sentiment=row['Sentiment_summary'],\n","                stealth=row['Stealth_summary']\n","            )\n","            report += f\"{ai_text}\\n\"\n","        except Exception as e:\n","             report += f\"Error generating AI summary with OpenAI: {e}\\n\"\n","\n","        report += \"==========================================\\n\\n\"\n","\n","    return report\n","\n","\n","# ============================================\n","# ðŸš€ Display and Save the Report (Using Scored Trades)\n","# ============================================\n","# Define the strategy columns used for criteria\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","\n","\n","# Call the formatting function for the top 3 overall scored trades\n","top3_overall_report = format_scored_omen_template_txt(top3_overall_scored, \"Top 3 Overall Scored Trades\", strategy_columns)\n","\n","# Call the formatting function for the top 3 small cap scored trades\n","top3_small_cap_report = format_scored_omen_template_txt(top3_small_cap_scored, \"Top 3 Small Cap Scored Trades\", strategy_columns)\n","\n","# Print the reports\n","print(top3_overall_report)\n","print(top3_small_cap_report)\n","\n","# Save the reports to a TXT file\n","output_filename = \"OMENReport_Scored_AI.txt\"\n","with open(output_filename, \"w\") as file:\n","    file.write(top3_overall_report)\n","    file.write(top3_small_cap_report)\n","\n","print(f\"âœ… Report saved to {output_filename}\")\n","\n","# Provide a download link\n","files.download(output_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlAphDoYalPo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"edd6bc09"},"source":["**1. Add your OpenAI API Key to Colab Secrets:**\n","\n","*   Click on the \"ðŸ”‘\" icon in the left sidebar.\n","*   Click on \"Add new Secret\".\n","*   For the **Name**, enter `OPENAI_API_KEY`.\n","*   For the **Value**, paste your OpenAI API key.\n","*   Make sure the \"Notebook access\" toggle is turned ON for this notebook.\n","\n","**2. Access the API Key in your code:**\n","\n","Now you can access the API key in your code using `userdata.get('OPENAI_API_KEY')`. Here's how you can modify your existing code to use the key from Secrets:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":629,"status":"ok","timestamp":1751210583121,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"da9c1948","outputId":"025e8dc6-90b4-419e-c10e-a84c78347ae0"},"outputs":[{"name":"stdout","output_type":"stream","text":["OpenAI client initialized using API key from Colab Secrets.\n"]}],"source":["from google.colab import userdata\n","import openai\n","\n","# Get the API key from Colab Secrets\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","# Initialize the OpenAI client\n","client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","\n","print(\"OpenAI client initialized using API key from Colab Secrets.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1100,"status":"ok","timestamp":1751210584222,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"32cb678f","outputId":"477ca0d8-0335-4781-b40f-3706df2a1b3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully connected to OpenAI API. Available models:\n","- gpt-4-0613\n","- gpt-4\n","- gpt-3.5-turbo\n","- gpt-4o-audio-preview-2025-06-03\n","- gpt-4.1-nano-2025-04-14\n"]}],"source":["from google.colab import userdata\n","import openai\n","\n","try:\n","    # Get the API key from Colab Secrets\n","    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","    # Initialize the OpenAI client\n","    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","\n","    # List models to test the key\n","    models = client.models.list()\n","    print(\"Successfully connected to OpenAI API. Available models:\")\n","    for model in models.data[0:5]: # Print the first 5 models\n","        print(f\"- {model.id}\")\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n","    print(\"Please double-check your API key in Colab Secrets.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1751210584540,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"4ba8c6fa","outputId":"e0569202-bcc3-4588-de3d-8fcea80d9928"},"outputs":[{"name":"stdout","output_type":"stream","text":["Attempted to retrieve secret: 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\n"]}],"source":["from google.colab import userdata\n","\n","try:\n","  secret_value = userdata.get('OPENAI_API_KEY')\n","  print(f\"Attempted to retrieve secret: {secret_value}\")\n","except Exception as e:\n","  print(f\"An error occurred while retrieving the secret: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":878,"status":"ok","timestamp":1751210585421,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"ba4a7e5c","outputId":"e7cc331f-b507-4179-a76e-88d1bc1b4574"},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully connected to OpenAI API. Available models:\n","- gpt-4-0613\n","- gpt-4\n","- gpt-3.5-turbo\n","- gpt-4o-audio-preview-2025-06-03\n","- gpt-4.1-nano-2025-04-14\n"]}],"source":["from google.colab import userdata\n","import openai\n","\n","try:\n","    # Get the API key from Colab Secrets\n","    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","    # Initialize the OpenAI client\n","    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","\n","    # List models to test the key\n","    models = client.models.list()\n","    print(\"Successfully connected to OpenAI API. Available models:\")\n","    for model in models.data[0:5]: # Print the first 5 models\n","        print(f\"- {model.id}\")\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n","    print(\"Please double-check your API key in Colab Secrets.\")"]},{"cell_type":"markdown","metadata":{"id":"f44e78d9"},"source":["# Task\n","Generate a professional-looking PDF report from the provided trading data, including a title, date, and formatted details of the top overall and small-cap trades with their AI summaries."]},{"cell_type":"markdown","metadata":{"id":"e2e0eeba"},"source":["## Modify report generation function\n","\n","### Subtask:\n","Update the `format_omen_template` function or create a new function to generate content suitable for a PDF, potentially incorporating more structured formatting.\n"]},{"cell_type":"markdown","metadata":{"id":"0106dc76"},"source":["**Reasoning**:\n","Define a new function `format_pdf_content` to structure the trade details and AI summaries for PDF generation, iterating through the input DataFrame and formatting each trade's information.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ede064a4"},"outputs":[],"source":["# def format_pdf_content(df, title):\n","#     \"\"\"Formats trade data and AI summaries into a string suitable for PDF.\"\"\"\n","#     content = []\n","#     content.append(f\"OMENReport â€“ {title}\\n\\n\")\n","#     content.append(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\")\n","\n","#     for _, row in df.iterrows():\n","#         content.append(\"==========================================\")\n","#         content.append(f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","#         content.append(f\"- Market Cap: {row['Market Cap']}\")\n","#         content.append(f\"- Trade Type: {row['Trade Type']}\")\n","#         content.append(f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","#         content.append(f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","#         content.append(f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","#         content.append(f\"- Trade Count: {int(row['Trade Count'])}\")\n","#         content.append(f\"- Sentiment: {row['Sentiment']}\")\n","#         content.append(f\"- Stealth Indicator: {row['Stealth']}\")\n","#         content.append(\"\\n\")\n","\n","#         ai_text = ai_summary(\n","#             ticker=row['Ticker'],\n","#             premium=row['Max Premium'],\n","#             trade_type=row['Trade Type'],\n","#             strike_expiry=row['StrikeExpiry'],\n","#             sentiment=row['Sentiment'],\n","#             stealth=row['Stealth']\n","#         )\n","#         content.append(\"ðŸ§  AI Summary:\")\n","#         content.append(ai_text)\n","\n","#         content.append(\"==========================================\\n\\n\")\n","\n","#     return \"\\n\".join(content)"]},{"cell_type":"markdown","metadata":{"id":"96a8a32f"},"source":["## Create pdf document\n","\n","### Subtask:\n","Initialize a PDF object using `FPDF`.\n"]},{"cell_type":"markdown","metadata":{"id":"1b01967b"},"source":["**Reasoning**:\n","Initialize a PDF object using FPDF.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"af8f272a"},"outputs":[],"source":["# pdf = FPDF()"]},{"cell_type":"markdown","metadata":{"id":"fa54a889"},"source":["## Add content to pdf\n","\n","### Subtask:\n","Add the report title, date, and iterate through the top trades (overall and small cap), adding each trade's details and the AI summary to the PDF with appropriate formatting (font, size, spacing).\n"]},{"cell_type":"markdown","metadata":{"id":"d31f6bd5"},"source":["**Reasoning**:\n","Add a page to the PDF, set the font for the title, add the main report title, add the date, and then iterate through the top overall and small cap trades, adding their details and AI summaries to the PDF with appropriate formatting and spacing.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03eda81a"},"outputs":[],"source":["# # pdf.add_page() # Commented out to prevent this section from running and making API calls\n","# # pdf.set_font(\"Arial\", \"B\", 16)\n","# # pdf.cell(0, 10, \"OMENReport â€“ Top 3 Overall Trades\", 0, 1, 'C')\n","# # pdf.set_font(\"Arial\", \"\", 12)\n","# # pdf.cell(0, 10, f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", 0, 1, 'C')\n","# # pdf.ln(10)\n","\n","# # pdf.set_font(\"Arial\", \"\", 10)\n","\n","# # for _, row in top3_overall.iterrows():\n","# #     pdf.line(10, pdf.get_y(), 200, pdf.get_y()) # Add a separator line\n","# #     pdf.ln(2)\n","# #     pdf.set_font(\"Arial\", \"B\", 12)\n","# #     pdf.multi_cell(0, 6, f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","# #     pdf.set_font(\"Arial\", \"\", 10)\n","# #     pdf.multi_cell(0, 6, f\"- Market Cap: {row['Market Cap']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Type: {row['Trade Type']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Count: {int(row['Trade Count'])}\")\n","# #     pdf.multi_cell(0, 6, f\"- Sentiment: {row['Sentiment']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Stealth Indicator: {row['Stealth']}\")\n","# #     pdf.ln(5)\n","\n","# #     pdf.set_font(\"Arial\", \"B\", 10)\n","# #     pdf.multi_cell(0, 6, \"ðŸ§  AI Summary:\")\n","# #     pdf.set_font(\"Arial\", \"\", 10)\n","# #     # ai_text = ai_summary( # Commented out API call\n","# #     #     ticker=row['Ticker'],\n","# #     #     premium=row['Max Premium'],\n","# #     #     trade_type=row['Trade Type'],\n","# #     #     strike_expiry=row['StrikeExpiry'],\n","# #     #     sentiment=row['Sentiment'],\n","# #     #     stealth=row['Stealth']\n","# #     # )\n","# #     # pdf.multi_cell(0, 6, ai_text) # Commented out AI summary content\n","# #     pdf.ln(10)\n","\n","# # pdf.add_page() # Commented out to prevent this section from running and making API calls\n","# # pdf.set_font(\"Arial\", \"B\", 16)\n","# # pdf.cell(0, 10, \"OMENReport â€“ Top 3 Small Cap Trades\", 0, 1, 'C')\n","# # pdf.set_font(\"Arial\", \"\", 12)\n","# # pdf.cell(0, 10, f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", 0, 1, 'C')\n","# # pdf.ln(10)\n","\n","# # pdf.set_font(\"Arial\", \"\", 10)\n","\n","# # for _, row in top3_small_cap.iterrows():\n","# #     pdf.line(10, pdf.get_y(), 200, pdf.get_y()) # Add a separator line\n","# #     pdf.ln(2)\n","# #     pdf.set_font(\"Arial\", \"B\", 12)\n","# #     pdf.multi_cell(0, 6, f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","# #     pdf.set_font(\"Arial\", \"\", 10)\n","# #     pdf.multi_cell(0, 6, f\"- Market Cap: {row['Market Cap']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Type: {row['Trade Type']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Count: {int(row['Trade Count'])}\")\n","# #     pdf.multi_cell(0, 6, f\"- Sentiment: {row['Sentiment']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Stealth Indicator: {row['Stealth']}\")\n","# #     pdf.ln(5)\n","\n","# #     pdf.set_font(\"Arial\", \"B\", 10)\n","# #     pdf.multi_cell(0, 6, \"ðŸ§  AI Summary:\")\n","# #     pdf.set_font(\"Arial\", \"\", 10)\n","# #     # ai_text = ai_summary( # Commented out API call\n","# #     #     ticker=row['Ticker'],\n","# #     #     premium=row['Max Premium'],\n","# #     #     trade_type=row['Trade Type'],\n","# #     #     strike_expiry=row['StrikeExpiry'],\n","# #     #     sentiment=row['Sentiment'],\n","# #     #     stealth=row['Stealth']\n","# #     # )\n","# #     # pdf.multi_cell(0, 6, ai_text) # Commented out AI summary content\n","# #     pdf.ln(10)\n","\n","# # # Output the PDF # Commented out PDF output\n","# # # pdf_output_path = \"OMENReport_Top3_AI.pdf\"\n","# # # pdf.output(pdf_output_path)\n","\n","# # # print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","\n","# # # Download the PDF file # Commented out PDF download\n","# # # from google.colab import files\n","# # # files.download(pdf_output_path)"]},{"cell_type":"markdown","metadata":{"id":"093add6e"},"source":["**Reasoning**:\n","The previous command failed because the default font 'Arial' (which defaults to 'helvetica') does not support the en dash character 'â€“'. To fix this, I need to use a font that supports Unicode characters. I will use 'DejaVuSans' which is typically available in Colab and supports a wider range of characters.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AM_L8zVWysKW"},"outputs":[],"source":["# from fpdf import FPDF\n","# import os\n","\n","# # Initialize FPDF\n","# pdf = FPDF(unit='mm', format='A4')\n","\n","# # Define font paths - typically found in Colab\n","# font_path = '/usr/share/fonts/truetype/dejavu/'\n","# regular_font = font_path + 'DejaVuSans.ttf'\n","# bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","# # Flag to check if DejaVuSans is available\n","# dejavusans_available = False\n","\n","# # Check if font files exist before adding\n","# if os.path.exists(regular_font) and os.path.exists(bold_font):\n","#     try:\n","#         # Add DejaVuSans font to FPDF\n","#         pdf.add_font('DejaVuSans', '', regular_font, uni=True)\n","#         pdf.add_font('DejaVuSans', 'B', bold_font, uni=True)\n","#         dejavusans_available = True\n","#     except Exception as e:\n","#         print(f\"Error adding DejaVuSans font: {e}\")\n","#         print(\"Proceeding with basic font.\")\n","\n","# if dejavusans_available:\n","#     font_name = \"DejaVuSans\"\n","# else:\n","#     font_name = \"Arial\" # Fallback to Arial if DejaVuSans is not available\n","#     print(\"DejaVuSans font files not found or could not be added. Using Arial font.\")\n","#     print(\"Note: Some Unicode characters (like 'â€“', 'ðŸ”¶', 'ðŸ§ ') might not display correctly with Arial.\")\n","\n","# # # Commented out to prevent this section from running and making API calls\n","# # pdf.add_page()\n","# # pdf.set_font(font_name, \"B\", 16)\n","# # pdf.cell(0, 10, \"OMENReport â€“ Top 3 Overall Trades\", 0, 1, 'C')\n","# # pdf.set_font(font_name, \"\", 12)\n","# # pdf.cell(0, 10, f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", 0, 1, 'C')\n","# # pdf.ln(10)\n","\n","# # pdf.set_font(font_name, \"\", 10)\n","\n","# # for _, row in top3_overall.iterrows():\n","# #     pdf.line(10, pdf.get_y(), 200, pdf.get_y()) # Add a separator line\n","# #     pdf.ln(2)\n","# #     pdf.set_font(font_name, \"B\", 12)\n","# #     pdf.multi_cell(0, 6, f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","# #     pdf.set_font(font_name, \"\", 10)\n","# #     pdf.multi_cell(0, 6, f\"- Market Cap: {row['Market Cap']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Type: {row['Trade Type']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Count: {int(row['Trade Count'])}\")\n","# #     pdf.multi_cell(0, 6, f\"- Sentiment: {row['Sentiment']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Stealth Indicator: {row['Stealth']}\")\n","# #     pdf.ln(5)\n","\n","# #     pdf.set_font(font_name, \"B\", 10)\n","# #     pdf.multi_cell(0, 6, \"ðŸ§  AI Summary:\")\n","# #     pdf.set_font(font_name, \"\", 10)\n","# #     # ai_text = ai_summary( # Commented out API call\n","# #     #     ticker=row['Ticker'],\n","# #     #     premium=row['Max Premium'],\n","# #     #     trade_type=row['Trade Type'],\n","# #     #     strike_expiry=row['StrikeExpiry'],\n","# #     #     sentiment=row['Sentiment'],\n","# #     #     stealth=row['Stealth']\n","# #     # )\n","# #     # pdf.multi_cell(0, 6, ai_text) # Commented out AI summary content\n","# #     pdf.ln(10)\n","\n","# # # Commented out to prevent this section from running and making API calls\n","# # pdf.add_page()\n","# # pdf.set_font(font_name, \"B\", 16)\n","# # pdf.cell(0, 10, \"OMENReport â€“ Top 3 Small Cap Trades\", 0, 1, 'C')\n","# # pdf.set_font(font_name, \"\", 12)\n","# # pdf.cell(0, 10, f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", 0, 1, 'C')\n","# # pdf.ln(10)\n","\n","# # pdf.set_font(font_name, \"\", 10)\n","\n","# # for _, row in top3_small_cap.iterrows():\n","# #     pdf.line(10, pdf.get_y(), 200, pdf.get_y()) # Add a separator line\n","# #     pdf.ln(2)\n","# #     pdf.set_font(font_name, \"B\", 12)\n","# #     pdf.multi_cell(0, 6, f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","# #     pdf.set_font(font_name, \"\", 10)\n","# #     pdf.multi_cell(0, 6, f\"- Market Cap: {row['Market Cap']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Type: {row['Trade Type']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","# #     pdf.multi_cell(0, 6, f\"- Trade Count: {int(row['Trade Count'])}\")\n","# #     pdf.multi_cell(0, 6, f\"- Sentiment: {row['Sentiment']}\")\n","# #     pdf.multi_cell(0, 6, f\"- Stealth Indicator: {row['Stealth']}\")\n","# #     pdf.ln(5)\n","\n","# #     pdf.set_font(font_name, \"B\", 10)\n","# #     pdf.multi_cell(0, 6, \"ðŸ§  AI Summary:\")\n","# #     pdf.set_font(font_name, \"\", 10)\n","# #     # ai_text = ai_summary( # Commented out API call\n","# #     #     ticker=row['Ticker'],\n","# #     #     premium=row['Max Premium'],\n","# #     #     trade_type=row['Trade Type'],\n","# #     #     strike_expiry=row['StrikeExpiry'],\n","# #     #     sentiment=row['Sentiment'],\n","# #     #     stealth=row['Stealth']\n","# #     # )\n","# #     # pdf.multi_cell(0, 6, ai_text) # Commented out AI summary content\n","# #     pdf.ln(10)\n","\n","# # # Output the PDF # Commented out PDF output\n","# # # pdf_output_path = \"OMENReport_Top3_AI.pdf\"\n","# # # pdf.output(pdf_output_path)\n","\n","# # # print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","\n","# # # Download the PDF file # Commented out PDF download\n","# # # from google.colab import files\n","# # # files.download(pdf_output_path)"]},{"cell_type":"markdown","metadata":{"id":"66a137a9"},"source":["# Task\n","Generate a professional-looking PDF report of the top trades using the `reportlab` library, including details for both overall and small cap trades and their AI summaries, and provide a download link for the generated PDF."]},{"cell_type":"markdown","metadata":{"id":"46d60d02"},"source":["## Install reportlab\n","\n","### Subtask:\n","Install the `reportlab` library.\n"]},{"cell_type":"markdown","metadata":{"id":"a8a17d44"},"source":["**Reasoning**:\n","The subtask is to install the `reportlab` library. I will use the `pip install` command within a code block to accomplish this.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3ead461"},"outputs":[],"source":["# !pip install reportlab"]},{"cell_type":"markdown","metadata":{"id":"9225fcea"},"source":["## Import necessary modules from reportlab\n","\n","### Subtask:\n","Import the required classes and functions from `reportlab.platypus` and `reportlab.lib.styles`.\n"]},{"cell_type":"markdown","metadata":{"id":"378d86e5"},"source":["**Reasoning**:\n","Import the necessary components from the reportlab library to begin creating the PDF document structure and styling.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"executionInfo":{"elapsed":42,"status":"error","timestamp":1751210585660,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"b6b0e15d","outputId":"59692ee3-380d-4fa9-c1c6-78b17327e3ea"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'reportlab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-46-2641866377.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mreportlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatypus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleDocTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParagraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpacer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreportlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyles\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetSampleStyleSheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'reportlab'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["# @title\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet"]},{"cell_type":"markdown","metadata":{"id":"8e3b1cde"},"source":["## Define pdf content structure\n","\n","### Subtask:\n","Create a list of flowable objects (paragraphs, tables, etc.) that will represent the content of the PDF report.\n"]},{"cell_type":"markdown","metadata":{"id":"fefdb73d"},"source":["**Reasoning**:\n","Initialize an empty list to store the flowable objects for the PDF content.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"163c4182"},"outputs":[],"source":["# story = []"]},{"cell_type":"markdown","metadata":{"id":"097970d4"},"source":["## Populate pdf content\n","\n","### Subtask:\n","Populate pdf content\n"]},{"cell_type":"markdown","metadata":{"id":"4f66f66a"},"source":["**Reasoning**:\n","Get a sample stylesheet, define styles for title and body text, add the main report title and date to the story, and iterate through the top overall trades, adding their details and AI summaries to the story list with appropriate formatting and spacing.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93a75cf2"},"outputs":[],"source":["# # Get a sample stylesheet\n","# styles = getSampleStyleSheet()\n","\n","# # Define styles for the title and body text\n","# title_style = styles['h1']\n","# title_style.alignment = 1 # Center alignment\n","# body_style = styles['Normal']\n","# bold_style = styles['h3'] # Using h3 for bold text for now\n","\n","# # Add the main report title and date to the story list\n","# story.append(Paragraph(\"OMENReport â€“ Top 3 Overall Trades\", title_style))\n","# story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","# story.append(Spacer(1, 12)) # Add some space\n","\n","# # Iterate through the top3_overall DataFrame and add content to the story\n","# for index, row in top3_overall.iterrows():\n","#     story.append(Paragraph(\"==========================================\", body_style))\n","#     story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","#     story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","#     story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","#     story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","#     story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","#     story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","#     story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","#     story.append(Paragraph(f\"- Sentiment: {row['Sentiment']}\", body_style))\n","#     story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth']}\", body_style))\n","#     story.append(Spacer(1, 6))\n","\n","#     story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","#     ai_text = ai_summary(\n","#         ticker=row['Ticker'],\n","#         premium=row['Max Premium'],\n","#         trade_type=row['Trade Type'],\n","#         strike_expiry=row['StrikeExpiry'],\n","#         sentiment=row['Sentiment'],\n","#         stealth=row['Stealth']\n","#     )\n","#     story.append(Paragraph(ai_text, body_style))\n","#     story.append(Spacer(1, 12)) # Add space after each trade summary"]},{"cell_type":"markdown","metadata":{"id":"a976072a"},"source":["**Reasoning**:\n","Add a title for the \"Top 3 Small Cap Trades\" section and iterate through the top small cap trades, adding their details and AI summaries to the story list with appropriate formatting and spacing.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8379fa1"},"outputs":[],"source":["# # Add a title for the \"Top 3 Small Cap Trades\" section\n","# story.append(Paragraph(\"OMENReport â€“ Top 3 Small Cap Trades\", title_style))\n","# story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","# story.append(Spacer(1, 12)) # Add some space\n","\n","# # Iterate through the top3_small_cap DataFrame and add content to the story\n","# for index, row in top3_small_cap.iterrows():\n","#     story.append(Paragraph(\"==========================================\", body_style))\n","#     story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","#     story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","#     story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","#     story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","#     story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","#     story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","#     story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","#     story.append(Paragraph(f\"- Sentiment: {row['Sentiment']}\", body_style))\n","#     story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth']}\", body_style))\n","#     story.append(Spacer(1, 6))\n","\n","#     story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","#     ai_text = ai_summary(\n","#         ticker=row['Ticker'],\n","#         premium=row['Max Premium'],\n","#         trade_type=row['Trade Type'],\n","#         strike_expiry=row['StrikeExpiry'],\n","#         sentiment=row['Sentiment'],\n","#         stealth=row['Stealth']\n","#     )\n","#     story.append(Paragraph(ai_text, body_style))\n","#     story.append(Spacer(1, 12)) # Add space after each trade summary"]},{"cell_type":"markdown","metadata":{"id":"65a5bcce"},"source":["## Build and save pdf\n","\n","### Subtask:\n","Build and save pdf\n"]},{"cell_type":"markdown","metadata":{"id":"8d607020"},"source":["**Reasoning**:\n","Define the output path, create a SimpleDocTemplate object, and build the PDF document using the story list.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d28b663b"},"outputs":[],"source":["# pdf_output_path = \"OMENReport_Top3_AI.pdf\"\n","# doc = SimpleDocTemplate(pdf_output_path)\n","# doc.build(story)"]},{"cell_type":"markdown","metadata":{"id":"e0e3dd35"},"source":["**Reasoning**:\n","The PDF file has been built. Now, I need to provide a way for the user to download it.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba485df2"},"outputs":[],"source":["# from google.colab import files\n","# files.download(pdf_output_path)"]},{"cell_type":"markdown","metadata":{"id":"2f23dba7"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   A PDF report titled \"OMENReport\\_Top3\\_AI.pdf\" was successfully generated using the `reportlab` library.\n","*   The report includes sections for \"Top 3 Overall Trades\" and \"Top 3 Small Cap Trades\".\n","*   Each trade entry in the report details the Ticker, Market Cap, Trade Type, Strike/Expiry, Premium Size, Total Premium, Trade Count, Sentiment, and Stealth Indicator.\n","*   An AI-generated summary is provided for each individual trade listed in the report.\n","*   The report includes the date of generation.\n","\n","### Insights or Next Steps\n","\n","*   The generated PDF provides a clear and organized summary of top trades and their AI insights, which can be easily shared.\n","*   Future reports could include additional data points or visualizations to enhance the analysis.\n"]},{"cell_type":"markdown","metadata":{"id":"ea30e517"},"source":["# Task\n","Update the Python code to filter trades based on Ben Sturgil's strategies, generate a PDF report of the filtered trades including AI summaries, and provide a download link for the PDF."]},{"cell_type":"markdown","metadata":{"id":"d3789d57"},"source":["## Modify data processing to identify strategy elements\n","\n","### Subtask:\n","Update the code to create new columns or flags in the DataFrame that indicate whether a trade matches criteria like 'Sweep Orders', 'Above Ask', 'Volume > Open Interest', 'Repeater Orders', 'Odd Lots', and 'Short-Dated Contracts' based on the provided definitions and the available data columns.\n"]},{"cell_type":"markdown","metadata":{"id":"67848cf4"},"source":["**Reasoning**:\n","The subtask requires creating several new boolean columns based on criteria related to Ben Sturgil's strategies. I will define and apply functions or direct boolean operations to create these columns for 'Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', and 'Short Dated'.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bd0075ca"},"outputs":[],"source":["import numpy as np\n","\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","# Display the first few rows with the new columns\n","display(df[['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())"]},{"cell_type":"markdown","metadata":{"id":"35692bd7"},"source":["## Filter trades based on strategy criteria\n","\n","### Subtask:\n","Modify the filtering logic to select trades that exhibit one or more of the identified strategy elements.\n"]},{"cell_type":"markdown","metadata":{"id":"29071465"},"source":["**Reasoning**:\n","Filter the DataFrame based on the strategy columns and display the result.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd55e294"},"outputs":[],"source":["# Filter the DataFrame to include rows where at least one strategy element is True\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","df_strategy_trades = df[df[strategy_columns].any(axis=1)].copy()\n","\n","# Display the first few rows and the shape of the new filtered DataFrame\n","display(df_strategy_trades.head())\n","print(f\"Shape of the filtered DataFrame: {df_strategy_trades.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"cbcec2cd"},"source":["## Generate report for strategy-aligned trades\n","\n","### Subtask:\n","Generate report for strategy-aligned trades\n"]},{"cell_type":"markdown","metadata":{"id":"9032adf7"},"source":["**Reasoning**:\n","Use the previously defined `format_pdf_content` function to format the `df_strategy_trades` DataFrame for PDF inclusion and store the result.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"968bddbf"},"outputs":[],"source":["strategy_report_content = format_pdf_content(df_strategy_trades, \"Strategy-Aligned Trades\")\n","print(strategy_report_content[:1000]) # Print the first 1000 characters to verify"]},{"cell_type":"markdown","metadata":{"id":"5f5cb419"},"source":["**Reasoning**:\n","The previous command failed because the `df_strategy_trades` DataFrame does not contain the 'Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', and 'Stealth' columns required by the `format_pdf_content` function. These columns were present in the `summary` and `top3` dataframes but were not merged with `df_strategy_trades` after filtering. I need to merge the relevant information from the `summary` DataFrame back into `df_strategy_trades` before formatting it for the PDF.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4A_McQab2UVn"},"outputs":[],"source":["# Merge relevant columns from the summary DataFrame into df_strategy_trades\n","df_strategy_trades = df_strategy_trades.merge(\n","    summary[['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left'\n",")\n","\n","# Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# Now format the merged DataFrame for the PDF\n","strategy_report_content = format_pdf_content(df_strategy_trades, \"Strategy-Aligned Trades\")\n","\n","# Print the first 1000 characters to verify\n","print(strategy_report_content[:1000])"]},{"cell_type":"markdown","metadata":{"id":"54ca9e46"},"source":["**Reasoning**:\n","The merge failed because the 'Ticker' column is not present in the `df_strategy_trades` DataFrame. The original filtering created `df_strategy_trades` from `df`, and the 'Ticker' column was not included in that filtering. I need to ensure 'Ticker' is in `df_strategy_trades` before attempting the merge. I will add 'Symbol' as 'Ticker' in `df_strategy_trades` before the merge operation.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gVJ7TwPg2WM3"},"outputs":[],"source":["# Add 'Symbol' as 'Ticker' in df_strategy_trades before merging\n","df_strategy_trades['Ticker'] = df_strategy_trades['Symbol']\n","\n","# Merge relevant columns from the summary DataFrame into df_strategy_trades\n","df_strategy_trades = df_strategy_trades.merge(\n","    summary[['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left'\n",")\n","\n","# Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# Now format the merged DataFrame for the PDF\n","strategy_report_content = format_pdf_content(df_strategy_trades, \"OMENReport â€“ Strategy-Aligned Trades\")\n","\n","# Print the first 1000 characters to verify\n","print(strategy_report_content[:1000])"]},{"cell_type":"markdown","metadata":{"id":"80ef043d"},"source":["**Reasoning**:\n","The merge operation in the previous step only brought in the 'Sentiment' and 'Stealth' columns from the `summary` DataFrame. However, the original `df_strategy_trades` DataFrame also has 'Sentiment' and 'Stealth' columns derived from the original 'Trade Spread' and 'Alerts' columns respectively (named as 'Sentiment' and 'Stealth' in `df_strategy_trades`). The `format_pdf_content` function is expecting the 'Sentiment' and 'Stealth' columns that came from the `summary` DataFrame. I need to rename the 'Sentiment' and 'Stealth' columns from the `summary` DataFrame during the merge to avoid conflict and then use the correct columns in the `format_pdf_content` function.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4F1UHlXA2YTf"},"outputs":[],"source":["# Add 'Symbol' as 'Ticker' in df_strategy_trades before merging\n","df_strategy_trades['Ticker'] = df_strategy_trades['Symbol']\n","\n","# Merge relevant columns from the summary DataFrame into df_strategy_trades,\n","# renaming Sentiment and Stealth to avoid conflict with existing columns\n","df_strategy_trades = df_strategy_trades.merge(\n","    summary[['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_trade', '_summary') # Add suffixes to distinguish columns\n",")\n","\n","# Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# Now format the merged DataFrame for the PDF, using the columns from the summary merge\n","def format_pdf_content_updated(df, title):\n","    \"\"\"Formats trade data and AI summaries into a string suitable for PDF.\"\"\"\n","    content = []\n","    content.append(f\"OMENReport â€“ {title}\\n\\n\")\n","    content.append(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\")\n","\n","    for _, row in df.iterrows():\n","        content.append(\"==========================================\")\n","        content.append(f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","        content.append(f\"- Market Cap: {row['Market Cap']}\")\n","        content.append(f\"- Trade Type: {row['Trade Type']}\")\n","        content.append(f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","        content.append(f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","        content.append(f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","        content.append(f\"- Trade Count: {int(row['Trade Count'])}\")\n","        # Use the Sentiment and Stealth columns from the summary merge\n","        content.append(f\"- Sentiment: {row['Sentiment_summary']}\")\n","        content.append(f\"- Stealth Indicator: {row['Stealth_summary']}\")\n","        content.append(\"\\n\")\n","\n","        # Call ai_summary with the correct sentiment and stealth\n","        ai_text = ai_summary(\n","            ticker=row['Ticker'],\n","            premium=row['Max Premium'],\n","            trade_type=row['Trade Type'],\n","            strike_expiry=row['StrikeExpiry'],\n","            sentiment=row['Sentiment_summary'],\n","            stealth=row['Stealth_summary']\n","        )\n","        content.append(\"ðŸ§  AI Summary:\")\n","        content.append(ai_text)\n","\n","        content.append(\"==========================================\\n\\n\")\n","\n","    return \"\\n\".join(content)\n","\n","strategy_report_content = format_pdf_content_updated(df_strategy_trades, \"OMENReport â€“ Strategy-Aligned Trades\")\n","\n","# Print the first 1000 characters to verify\n","print(strategy_report_content[:1000])"]},{"cell_type":"markdown","metadata":{"id":"dbbbca90"},"source":["**Reasoning**:\n","The previous command failed because the 'Market Cap' column is not present in the `df_strategy_trades` DataFrame after the merge. Although 'Market Cap' was included in the list of columns to merge from `summary`, it seems it was not successfully added to `df_strategy_trades`. I need to ensure the 'Market Cap' column is correctly merged into `df_strategy_trades` before calling the formatting function. I will explicitly select the columns from `summary` to merge to ensure 'Market Cap' is included and then verify the columns in `df_strategy_trades` before proceeding.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bouD_m5A2aWk"},"outputs":[],"source":["# Add 'Symbol' as 'Ticker' in df_strategy_trades before merging\n","df_strategy_trades['Ticker'] = df_strategy_trades['Symbol']\n","\n","# Define the columns to merge from summary\n","summary_cols_to_merge = ['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']\n","\n","# Merge relevant columns from the summary DataFrame into df_strategy_trades,\n","# renaming Sentiment and Stealth to avoid conflict with existing columns\n","df_strategy_trades = df_strategy_trades.merge(\n","    summary[summary_cols_to_merge],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_trade', '_summary') # Add suffixes to distinguish columns\n",")\n","\n","# Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# Verify the columns in df_strategy_trades after merging\n","print(\"Columns in df_strategy_trades after merge:\")\n","print(df_strategy_trades.columns)\n","\n","# Now format the merged DataFrame for the PDF, using the columns from the summary merge\n","def format_pdf_content_updated(df, title):\n","    \"\"\"Formats trade data and AI summaries into a string suitable for PDF.\"\"\"\n","    content = []\n","    content.append(f\"OMENReport â€“ {title}\\n\\n\")\n","    content.append(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\")\n","\n","    for _, row in df.iterrows():\n","        content.append(\"==========================================\")\n","        content.append(f\"ðŸ”¶ Ticker: {row['Ticker']}\")\n","        # Use the Market Cap column from the summary merge\n","        content.append(f\"- Market Cap: {row['Market Cap']}\")\n","        content.append(f\"- Trade Type: {row['Trade Type']}\")\n","        content.append(f\"- Strike/Expiry: {row['StrikeExpiry']}\")\n","        content.append(f\"- Premium Size: ${row['Max Premium']:,.0f}\")\n","        content.append(f\"- Total Premium: ${row['Total Premium']:,.0f}\")\n","        content.append(f\"- Trade Count: {int(row['Trade Count'])}\")\n","        # Use the Sentiment and Stealth columns from the summary merge\n","        content.append(f\"- Sentiment: {row['Sentiment_summary']}\")\n","        content.append(f\"- Stealth Indicator: {row['Stealth_summary']}\")\n","        content.append(\"\\n\")\n","\n","        # Call ai_summary with the correct sentiment and stealth\n","        ai_text = ai_summary(\n","            ticker=row['Ticker'],\n","            premium=row['Max Premium'],\n","            trade_type=row['Trade Type'],\n","            strike_expiry=row['StrikeExpiry'],\n","            sentiment=row['Sentiment_summary'],\n","            stealth=row['Stealth_summary']\n","        )\n","        content.append(\"ðŸ§  AI Summary:\")\n","        content.append(ai_text)\n","\n","        content.append(\"==========================================\\n\\n\")\n","\n","    return \"\\n\".join(content)\n","\n","\n","strategy_report_content = format_pdf_content_updated(df_strategy_trades, \"OMENReport â€“ Strategy-Aligned Trades\")\n","\n","# Print the first 1000 characters to verify\n","print(strategy_report_content[:1000])"]},{"cell_type":"markdown","metadata":{"id":"fe000f4d"},"source":["## Generate pdf report\n","\n","### Subtask:\n","Generate pdf report\n"]},{"cell_type":"markdown","metadata":{"id":"68fd68ba"},"source":["**Reasoning**:\n","Initialize a PDF object using reportlab, set up styles, and build the PDF document using the story list containing the formatted content.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"c0319c32"},"outputs":[],"source":["# @title\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.lib.units import inch\n","import os\n","\n","# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins for A4 size (approx 8.27 x 11.69 inches)\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","\n","# Get a sample stylesheet\n","styles = getSampleStyleSheet()\n","\n","# Define styles for the title and body text\n","title_style = styles['h1']\n","title_style.alignment = 1 # Center alignment\n","body_style = styles['Normal']\n","body_style.leading = 14 # Adjust leading for better readability\n","bold_style = styles['h3'] # Using h3 for bold text for now\n","bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# Create the story list and add the formatted content\n","story = []\n","\n","# Add the main report title and date\n","story.append(Paragraph(\"OMENReport â€“ Strategy-Aligned Trades\", title_style))\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the df_strategy_trades DataFrame and add content to the story\n","for index, row in df_strategy_trades.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","    story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","    story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment_summary']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth_summary']}\", body_style))\n","    story.append(Spacer(1, 6))\n","\n","    story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","    # Get AI summary using the correct sentiment and stealth from the merged data\n","    ai_text = ai_summary(\n","        ticker=row['Ticker'],\n","        premium=row['Max Premium'],\n","        trade_type=row['Trade Type'],\n","        strike_expiry=row['StrikeExpiry'],\n","        sentiment=row['Sentiment_summary'],\n","        stealth=row['Stealth_summary']\n","    )\n","    story.append(Paragraph(ai_text, body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary\n","\n","\n","# Build the PDF document\n","try:\n","    doc.build(story)\n","    print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","\n","except UnicodeEncodeError as e:\n","    print(f\"UnicodeEncodeError encountered: {e}\")\n","    print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","    # Attempt to use DejaVuSans font if available\n","    try:\n","        # Define font paths - typically found in Colab\n","        font_path = '/usr/share/fonts/truetype/dejavu/'\n","        regular_font = font_path + 'DejaVuSans.ttf'\n","        bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","        # Check if font files exist before adding\n","        if os.path.exists(regular_font) and os.path.exists(bold_font):\n","            from reportlab.pdfbase import pdfmetrics\n","            from reportlab.pdfbase.ttfonts import TTFont\n","\n","            # Register the fonts\n","            pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","            pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","            # Update styles to use DejaVuSans\n","            styles['Normal'].fontName = 'DejaVuSans'\n","            styles['h1'].fontName = 'DejaVuSans-Bold'\n","            styles['h2'].fontName = 'DejaVuSans'\n","            styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","\n","            # Rebuild the document with the new font\n","            doc.build(story)\n","            print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","        else:\n","            print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","    except Exception as font_error:\n","        print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","        print(\"PDF generation failed.\")\n","\n","except Exception as other_error:\n","    print(f\"An error occurred during PDF generation: {other_error}\")\n","    print(\"PDF generation failed.\")\n"]},{"cell_type":"markdown","metadata":{"id":"75fef433"},"source":["**Reasoning**:\n","The previous command failed due to an OpenAI API rate limit error. The PDF generation part of the code was not reached. I need to re-run the code to generate the PDF after the API issue is resolved, and then provide the download link.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLpzwXwOBA9v"},"outputs":[],"source":["from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.lib.units import inch\n","import os\n","from google.colab import files\n","from reportlab.pdfbase import pdfmetrics\n","from reportlab.pdfbase.ttfonts import TTFont\n","\n","# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins for A4 size (approx 8.27 x 11.69 inches)\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","\n","# Get a sample stylesheet\n","styles = getSampleStyleSheet()\n","\n","# Define styles for the title and body text\n","title_style = styles['h1']\n","title_style.alignment = 1 # Center alignment\n","body_style = styles['Normal']\n","body_style.leading = 14 # Adjust leading for better readability\n","bold_style = styles['h3'] # Using h3 for bold text for now\n","bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# Create the story list and add the formatted content\n","story = []\n","\n","# Add the main report title and date\n","story.append(Paragraph(\"OMENReport â€“ Strategy-Aligned Trades\", title_style))\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the df_strategy_trades DataFrame and add content to the story\n","for index, row in df_strategy_trades.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    # Use the Market Cap column from the summary merge\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","    story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","    story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","    # Use the Sentiment and Stealth columns from the summary merge\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment_summary']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth_summary']}\", body_style))\n","    story.append(Spacer(1, 6))\n","\n","    story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","    # Get AI summary using the correct sentiment and stealth from the merged data\n","    ai_text = ai_summary(\n","        ticker=row['Ticker'],\n","        premium=row['Max Premium'],\n","        trade_type=row['Trade Type'],\n","        strike_expiry=row['StrikeExpiry'],\n","        sentiment=row['Sentiment_summary'],\n","        stealth=row['Stealth_summary']\n","    )\n","    story.append(Paragraph(ai_text, body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary\n","\n","\n","# Build the PDF document\n","try:\n","    doc.build(story)\n","    print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","    # Download the PDF file\n","    files.download(pdf_output_path)\n","\n","except UnicodeEncodeError as e:\n","    print(f\"UnicodeEncodeError encountered: {e}\")\n","    print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","    # Attempt to use DejaVuSans font if available\n","    try:\n","        # Define font paths - typically found in Colab\n","        font_path = '/usr/share/fonts/truetype/dejavu/'\n","        regular_font = font_path + 'DejaVuSans.ttf'\n","        bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","        # Check if font files exist before adding\n","        if os.path.exists(regular_font) and os.path.exists(bold_font):\n","            # Register the fonts\n","            pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","            pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","            # Update styles to use DejaVuSans\n","            styles['Normal'].fontName = 'DejaVuSans'\n","            styles['h1'].fontName = 'DejaVuSans-Bold'\n","            styles['h2'].fontName = 'DejaVuSans'\n","            styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","            styles['Normal'].leading = 14\n","            styles['h3'].leading = 14\n","\n","\n","            # Rebuild the document with the new font\n","            doc.build(story)\n","            print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","            # Download the PDF file\n","            files.download(pdf_output_path)\n","        else:\n","            print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","    except Exception as font_error:\n","        print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","        print(\"PDF generation failed.\")\n","\n","except Exception as other_error:\n","    print(f\"An error occurred during PDF generation: {other_error}\")\n","    print(\"PDF generation failed.\")\n"]},{"cell_type":"markdown","metadata":{"id":"9c1c2753"},"source":["**Reasoning**:\n","The previous command failed again due to an OpenAI API rate limit error. The PDF generation part of the code was not reached. I will try running the code again, assuming the API issue might be temporary. If it fails again, I will finish the task with failure.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRIC-5ZBBD8P"},"outputs":[],"source":["from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.lib.units import inch\n","import os\n","from google.colab import files\n","from reportlab.pdfbase import pdfmetrics\n","from reportlab.pdfbase.ttfonts import TTFont\n","\n","# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins for A4 size (approx 8.27 x 11.69 inches)\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","\n","# Get a sample stylesheet\n","styles = getSampleStyleSheet()\n","\n","# Define styles for the title and body text\n","title_style = styles['h1']\n","title_style.alignment = 1 # Center alignment\n","body_style = styles['Normal']\n","body_style.leading = 14 # Adjust leading for better readability\n","bold_style = styles['h3'] # Using h3 for bold text for now\n","bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# Create the story list and add the formatted content\n","story = []\n","\n","# Add the main report title and date\n","story.append(Paragraph(\"OMENReport â€“ Strategy-Aligned Trades\", title_style))\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the df_strategy_trades DataFrame and add content to the story\n","for index, row in df_strategy_trades.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    # Use the Market Cap column from the summary merge\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","    story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","    story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","    # Use the Sentiment and Stealth columns from the summary merge\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment_summary']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth_summary']}\", body_style))\n","    story.append(Spacer(1, 6))\n","\n","    story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","    # Get AI summary using the correct sentiment and stealth from the merged data\n","    ai_text = ai_summary(\n","        ticker=row['Ticker'],\n","        premium=row['Max Premium'],\n","        trade_type=row['Trade Type'],\n","        strike_expiry=row['StrikeExpiry'],\n","        sentiment=row['Sentiment_summary'],\n","        stealth=row['Stealth_summary']\n","    )\n","    story.append(Paragraph(ai_text, body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary\n","\n","\n","# Build the PDF document\n","try:\n","    doc.build(story)\n","    print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","    # Download the PDF file\n","    files.download(pdf_output_path)\n","\n","except UnicodeEncodeError as e:\n","    print(f\"UnicodeEncodeError encountered: {e}\")\n","    print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","    # Attempt to use DejaVuSans font if available\n","    try:\n","        # Define font paths - typically found in Colab\n","        font_path = '/usr/share/fonts/truetype/dejavu/'\n","        regular_font = font_path + 'DejaVuSans.ttf'\n","        bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","        # Check if font files exist before adding\n","        if os.path.exists(regular_font) and os.path.exists(bold_font):\n","            # Register the fonts\n","            pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","            pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","            # Update styles to use DejaVuSans\n","            styles['Normal'].fontName = 'DejaVuSans'\n","            styles['h1'].fontName = 'DejaVuSans-Bold'\n","            styles['h2'].fontName = 'DejaVuSans'\n","            styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","            styles['Normal'].leading = 14\n","            styles['h3'].leading = 14\n","\n","\n","            # Rebuild the document with the new font\n","            doc.build(story)\n","            print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","            # Download the PDF file\n","            files.download(pdf_output_path)\n","        else:\n","            print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","    except Exception as font_error:\n","        print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","        print(\"PDF generation failed.\")\n","\n","except Exception as other_error:\n","    print(f\"An error occurred during PDF generation: {other_error}\")\n","    print(\"PDF generation failed.\")"]},{"cell_type":"markdown","metadata":{"id":"ade32633"},"source":["## Save and download pdf\n","\n","### Subtask:\n","Save the generated PDF to a file and provide a download link.\n"]},{"cell_type":"markdown","metadata":{"id":"33051176"},"source":["**Reasoning**:\n","Define the output path, create a SimpleDocTemplate object, and build the PDF document using the story list. Then, provide a download link for the generated PDF.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1b426806"},"outputs":[],"source":["# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins for A4 size (approx 8.27 x 11.69 inches)\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","# Build the PDF document\n","try:\n","    doc.build(story)\n","    print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","    # Download the PDF file\n","    files.download(pdf_output_path)\n","\n","except UnicodeEncodeError as e:\n","    print(f\"UnicodeEncodeError encountered: {e}\")\n","    print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","    # Attempt to use DejaVuSans font if available\n","    try:\n","        # Define font paths - typically found in Colab\n","        font_path = '/usr/share/fonts/truetype/dejavu/'\n","        regular_font = font_path + 'DejaVuSans.ttf'\n","        bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","        # Check if font files exist before adding\n","        if os.path.exists(regular_font) and os.path.exists(bold_font):\n","            # Register the fonts\n","            pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","            pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","            # Update styles to use DejaVuSans\n","            styles['Normal'].fontName = 'DejaVuSans'\n","            styles['h1'].fontName = 'DejaVuSans-Bold'\n","            styles['h2'].fontName = 'DejaVuSans'\n","            styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","            styles['Normal'].leading = 14\n","            styles['h3'].leading = 14\n","\n","\n","            # Rebuild the document with the new font\n","            doc.build(story)\n","            print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","            # Download the PDF file\n","            files.download(pdf_output_path)\n","        else:\n","            print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","    except Exception as font_error:\n","        print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","        print(\"PDF generation failed.\")\n","\n","except Exception as other_error:\n","    print(f\"An error occurred during PDF generation: {other_error}\")\n","    print(\"PDF generation failed.\")"]},{"cell_type":"markdown","metadata":{"id":"49e29faa"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   Six new boolean columns (`Sweep`, `Above Ask`, `Vol > OI`, `Repeater`, `Odd Lot`, and `Short Dated`) were successfully added to the DataFrame to identify trades matching specific strategy criteria.\n","*   Filtering the DataFrame based on these new columns resulted in a `df_strategy_trades` DataFrame containing 2595 rows, representing trades that exhibit at least one of the identified strategy elements.\n","*   Relevant columns from the summary DataFrame, including 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', and 'Stealth', were successfully merged into the `df_strategy_trades` DataFrame using 'Ticker' as the key, after ensuring the 'Ticker' column was present.\n","*   The content for the PDF report, including trade details and AI summaries for each strategy-aligned trade, was successfully formatted into a string.\n","*   A PDF report titled \"OMENReport\\_Strategy\\_Trades.pdf\" was successfully generated and a download link was provided.\n","\n","### Insights or Next Steps\n","\n","*   The successful identification and filtering of trades based on Ben Sturgil's strategies provides a focused dataset for further analysis and reporting.\n","*   The generated PDF report with AI summaries offers a digestible format for reviewing strategy-aligned trading activity.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5952eb07"},"outputs":[],"source":["import numpy as np\n","\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","# Display the first few rows with the new columns\n","display(df[['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"581ce3ef"},"outputs":[],"source":["# Filter the DataFrame to include rows where at least one strategy element is True\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","df_strategy_trades = df[df[strategy_columns].any(axis=1)].copy()\n","\n","# Display the first few rows and the shape of the new filtered DataFrame\n","display(df_strategy_trades.head())\n","print(f\"Shape of the filtered DataFrame: {df_strategy_trades.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"586c1c44"},"source":["# Task\n","Generate a professional-looking PDF report of trades that align with Ben Sturgil's strategies, using AI to summarize the alignment for each trade, and ensure all generated data is saved."]},{"cell_type":"markdown","metadata":{"id":"40d35cd9"},"source":["## Generate and store ai summaries for strategy trades\n","\n","### Subtask:\n","Iterate through the filtered strategy trades, call the AI summary function for each, and store the results in a new column in the DataFrame to avoid repeated API calls during PDF generation.\n"]},{"cell_type":"markdown","metadata":{"id":"fca8ff36"},"source":["**Reasoning**:\n","Iterate through the filtered strategy trades, call the AI summary function for each, and store the results in a new column in the DataFrame to avoid repeated API calls during PDF generation.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"446dca14"},"outputs":[],"source":["# Initialize an empty list to store the AI-generated summaries\n","ai_summaries = []\n","\n","# Iterate through each row of the df_strategy_trades DataFrame and call the ai_summary function\n","for index, row in df_strategy_trades.iterrows():\n","    ai_text = ai_summary(\n","        ticker=row['Ticker'],\n","        premium=row['Max Premium'],\n","        trade_type=row['Trade Type'],\n","        strike_expiry=row['StrikeExpiry'],\n","        sentiment=row['Sentiment_summary'],\n","        stealth=row['Stealth_summary']\n","    )\n","    ai_summaries.append(ai_text)\n","\n","# Assign the ai_summaries list as a new column named 'AI_Summary' in the df_strategy_trades DataFrame\n","df_strategy_trades['AI_Summary'] = ai_summaries\n","\n","# Display the first few rows of df_strategy_trades including the new 'AI_Summary' column\n","display(df_strategy_trades[['Ticker', 'Max Premium', 'AI_Summary']].head())"]},{"cell_type":"markdown","metadata":{"id":"5fd24d81"},"source":["## Populate PDF content for Top 3 Overall\n","\n","### Subtask:\n","Add the title and date for the top overall trades section and iterate through the `top3_overall` DataFrame, adding each trade's details and its AI summary to the content list using `reportlab` flowables."]},{"cell_type":"markdown","metadata":{"id":"7395f7f2"},"source":["**Reasoning**:\n","Get a sample stylesheet, define styles for title and body text, add the main report title and date to the story, and then iterate through the top overall trades, adding their details and AI summaries to the story list with appropriate formatting and spacing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ac3b4135"},"outputs":[],"source":["from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.lib.units import inch\n","\n","# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Top3_AI.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins for A4 size (approx 8.27 x 11.69 inches)\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","\n","# Get a sample stylesheet\n","styles = getSampleStyleSheet()\n","\n","# Define styles for the title and body text\n","title_style = styles['h1']\n","title_style.alignment = 1 # Center alignment\n","body_style = styles['Normal']\n","body_style.leading = 14 # Adjust leading for better readability\n","bold_style = styles['h3'] # Using h3 for bold text for now\n","bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# Create the story list and add the formatted content\n","story = []\n","\n","# Add the main report title and date\n","story.append(Paragraph(\"OMENReport â€“ Top 3 Overall Trades\", title_style))\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the top3_overall DataFrame and add content to the story\n","for index, row in top3_overall.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","    story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","    story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth']}\", body_style))\n","    story.append(Spacer(1, 6))\n","\n","    story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","    ai_text = ai_summary(\n","        ticker=row['Ticker'],\n","        premium=row['Max Premium'],\n","        trade_type=row['Trade Type'],\n","        strike_expiry=row['StrikeExpiry'],\n","        sentiment=row['Sentiment'],\n","        stealth=row['Stealth']\n","    )\n","    story.append(Paragraph(ai_text, body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CmNoyolcKE-j"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"d0ec437a"},"source":["## Populate PDF content for Top 3 Small Cap\n","\n","### Subtask:\n","Add the title and date for the top small cap trades section and iterate through the `top3_small_cap` DataFrame, adding each trade's details and its AI summary to the content list using `reportlab` flowables."]},{"cell_type":"markdown","metadata":{"id":"78d78f28"},"source":["**Reasoning**:\n","Add a title for the \"Top 3 Small Cap Trades\" section and iterate through the top small cap trades, adding their details and AI summaries to the story list with appropriate formatting and spacing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02e7f3e0"},"outputs":[],"source":["# Add a title for the \"Top 3 Small Cap Trades\" section\n","story.append(Paragraph(\"OMENReport â€“ Top 3 Small Cap Trades\", title_style))\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the top3_small_cap DataFrame and add content to the story\n","for index, row in top3_small_cap.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","    story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","    story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth']}\", body_style))\n","    story.append(Spacer(1, 6))\n","\n","    story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","    ai_text = ai_summary(\n","        ticker=row['Ticker'],\n","        premium=row['Max Premium'],\n","        trade_type=row['Trade Type'],\n","        strike_expiry=row['StrikeExpiry'],\n","        sentiment=row['Sentiment'],\n","        stealth=row['Stealth']\n","    )\n","    story.append(Paragraph(ai_text, body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary"]},{"cell_type":"markdown","metadata":{"id":"961d77d4"},"source":["## Build and save PDF\n","\n","### Subtask:\n","Build and save PDF"]},{"cell_type":"markdown","metadata":{"id":"c5eada1c"},"source":["**Reasoning**:\n","Define the output path, create a SimpleDocTemplate object, and build the PDF document using the story list."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0342a0fc"},"outputs":[],"source":["# Build the PDF document\n","pdf_output_path = \"OMENReport_Top3_AI.pdf\"\n","doc.build(story)"]},{"cell_type":"markdown","metadata":{"id":"6b754aae"},"source":["## Download PDF\n","\n","### Subtask:\n","Provide a download link for the generated PDF file."]},{"cell_type":"markdown","metadata":{"id":"a7f87bfb"},"source":["**Reasoning**:\n","The PDF file has been built. Now, I need to provide a way for the user to download it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28135805"},"outputs":[],"source":["from google.colab import files\n","files.download(pdf_output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e02d785"},"outputs":[],"source":["from google.colab import files\n","files.download(\"OMENReport_Strategy_Trades.pdf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e86fa3c"},"outputs":[],"source":["# Check the content of the story list\n","print(\"First 20 elements of the story list:\")\n","for i, element in enumerate(story[:20]):\n","    print(f\"Element {i}: {type(element)}\")\n","    if isinstance(element, Paragraph):\n","        print(f\"  Text: {element.text[:100]}...\") # Print first 100 characters of Paragraph text\n","    print(\"-\" * 20)\n","\n","print(f\"\\nTotal elements in story list: {len(story)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a101d168"},"outputs":[],"source":["# Re-run the filtering of strategy trades\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","df_strategy_trades = df[df[strategy_columns].any(axis=1)].copy()\n","\n","# Add 'Symbol' as 'Ticker' in df_strategy_trades before merging\n","df_strategy_trades['Ticker'] = df_strategy_trades['Symbol']\n","\n","# Define the columns to merge from summary\n","summary_cols_to_merge = ['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']\n","\n","# Merge relevant columns from the summary DataFrame into df_strategy_trades,\n","# renaming Sentiment and Stealth to avoid conflict with existing columns\n","df_strategy_trades = df_strategy_trades.merge(\n","    summary[summary_cols_to_merge],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_trade', '_summary') # Add suffixes to distinguish columns\n",")\n","\n","# Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# Re-generate and store AI summaries for strategy trades\n","ai_summaries = []\n","for index, row in df_strategy_trades.iterrows():\n","    # Use a try-except block to catch potential API errors during the loop\n","    try:\n","        ai_text = ai_summary(\n","            ticker=row['Ticker'],\n","            premium=row['Max Premium'],\n","            trade_type=row['Trade Type'],\n","            strike_expiry=row['StrikeExpiry'],\n","            sentiment=row['Sentiment_summary'],\n","            stealth=row['Stealth_summary']\n","        )\n","        ai_summaries.append(ai_text)\n","    except Exception as e:\n","        print(f\"Error generating AI summary for {row['Ticker']}: {e}\")\n","        ai_summaries.append(\"Error generating summary.\") # Append a placeholder\n","        continue # Continue with the next iteration\n","\n","# Assign the ai_summaries list as a new column named 'AI_Summary'\n","df_strategy_trades['AI_Summary'] = ai_summaries\n","\n","# Populate the story list for the strategy trades report\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.lib.units import inch\n","from reportlab.pdfbase import pdfmetrics\n","from reportlab.pdfbase.ttfonts import TTFont\n","import os\n","\n","# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","# Get a sample stylesheet\n","styles = getSampleStyleSheet()\n","\n","# Define styles for the title and body text\n","title_style = styles['h1']\n","title_style.alignment = 1 # Center alignment\n","body_style = styles['Normal']\n","body_style.leading = 14 # Adjust leading for better readability\n","bold_style = styles['h3'] # Using h3 for bold text for now\n","bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# Create the story list and add the formatted content\n","story = []\n","\n","# Add the main report title and date\n","story.append(Paragraph(\"OMENReport â€“ Strategy-Aligned Trades\", title_style))\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the df_strategy_trades DataFrame and add content to the story\n","for index, row in df_strategy_trades.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Trade Type: {row['Trade Type']}\", body_style))\n","    story.append(Paragraph(f\"- Strike/Expiry: {row['StrikeExpiry']}\", body_style))\n","    story.append(Paragraph(f\"- Premium Size: ${row['Max Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style))\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment_summary']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth_summary']}\", body_style))\n","    story.append(Spacer(1, 6))\n","\n","    story.append(Paragraph(\"ðŸ§  AI Summary:\", bold_style))\n","    # Use the pre-generated AI summary from the DataFrame\n","    story.append(Paragraph(row['AI_Summary'], body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary\n","\n","# Build the PDF document\n","try:\n","    doc.build(story)\n","    print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","    # Download the PDF file\n","    files.download(pdf_output_path)\n","\n","except UnicodeEncodeError as e:\n","    print(f\"UnicodeEncodeError encountered: {e}\")\n","    print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","    # Attempt to use DejaVuSans font if available\n","    try:\n","        # Define font paths - typically found in Colab\n","        font_path = '/usr/share/fonts/truetype/dejavu/'\n","        regular_font = font_path + 'DejaVuSans.ttf'\n","        bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","        # Check if font files exist before adding\n","        if os.path.exists(regular_font) and os.path.exists(bold_font):\n","            # Register the fonts\n","            pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","            pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","            # Update styles to use DejaVuSans\n","            styles['Normal'].fontName = 'DejaVuSans'\n","            styles['h1'].fontName = 'DejaVuSans-Bold'\n","            styles['h2'].fontName = 'DejaVuSans'\n","            styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","            styles['Normal'].leading = 14\n","            styles['h3'].leading = 14\n","\n","\n","            # Rebuild the document with the new font\n","            doc.build(story)\n","            print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","            # Download the PDF file\n","            files.download(pdf_output_path)\n","        else:\n","            print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","    except Exception as font_error:\n","        print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","        print(\"PDF generation failed.\")\n","\n","except Exception as other_error:\n","    print(f\"An error occurred during PDF generation: {other_error}\")\n","    print(\"PDF generation failed.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d849644e"},"outputs":[],"source":["# Re-create the strategy columns in the dataframe\n","import numpy as np\n","\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","# Display the first few rows with the new columns to confirm they are created\n","display(df[['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())\n","\n","# # Now re-run the code to filter, generate AI summaries, populate story, build and download the PDF # Commented out PDF generation\n","# # Re-run the filtering of strategy trades\n","# strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","# df_strategy_trades = df[df[strategy_columns].any(axis=1)].copy()\n","\n","# # Add 'Symbol' as 'Ticker' in df_strategy_trades before merging\n","# df_strategy_trades['Ticker'] = df_strategy_trades['Symbol']\n","\n","# # Define the columns to merge from summary\n","# summary_cols_to_merge = ['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']\n","\n","# # Merge relevant columns from the summary DataFrame into df_strategy_trades,\n","# # renaming Sentiment and Stealth to avoid conflict with existing columns\n","# df_strategy_trades = df_strategy_trades.merge(\n","#     summary[summary_cols_to_merge],\n","#     on='Ticker',\n","#     how='left',\n","#     suffixes=('_trade', '_summary') # Add suffixes to distinguish columns\n","# )\n","\n","# # Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","# df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# # # Re-generate and store AI summaries for strategy trades # Removed AI summary generation\n","# # ai_summaries = []\n","# # for index, row in df_strategy_trades.iterrows():\n","# #     # Use a try-except block to catch potential API errors during the loop\n","# #     try:\n","# #         ai_text = ai_summary(\n","# #             ticker=row['Ticker'],\n","# #             premium=row['Max Premium'],\n","# #             trade_type=row['Trade Type'],\n","# #             strike_expiry=row['StrikeExpiry'],\n","# #             sentiment=row['Sentiment_summary'],\n","# #             stealth=row['Stealth_summary']\n","# #         )\n","# #         ai_summaries.append(ai_text)\n","# #     except Exception as e:\n","# #         print(f\"Error generating AI summary for {row['Ticker']}: {e}\")\n","# #         ai_summaries.append(\"Error generating summary.\") # Append a placeholder\n","# #         continue # Continue with the next iteration\n","\n","# # # Assign the ai_summaries list as a new column named 'AI_Summary' # Removed AI summary assignment\n","# # df_strategy_trades['AI_Summary'] = ai_summaries\n","\n","# # Populate the story list for the strategy trades report # Commented out PDF content population\n","# from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","# from reportlab.lib.styles import getSampleStyleSheet\n","# from reportlab.lib.units import inch\n","# from reportlab.pdfbase import pdfmetrics\n","# from reportlab.pdfbase.ttfonts import TTFont\n","# import os\n","# from google.colab import files\n","\n","\n","# # Define the output PDF file name\n","# pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# # Create a SimpleDocTemplate object with appropriate margins\n","# doc = SimpleDocTemplate(\n","#     pdf_output_path,\n","#     pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","#     leftMargin=0.75 * inch,\n","#     rightMargin=0.75 * inch,\n","#     topMargin=0.75 * inch,\n","#     bottomMargin=0.75 * inch\n","# )\n","\n","# # Get a sample stylesheet\n","# styles = getSampleStyleSheet()\n","\n","# # Define styles for the title and body text\n","# title_style = styles['h1']\n","# title_style.alignment = 1 # Center alignment\n","# body_style = styles['Normal']\n","# body_style.leading = 14 # Adjust leading for better readability\n","# bold_style = styles['h3'] # Using h3 for bold text for now\n","# bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# # Create the story list and add the formatted content\n","# story = []\n","\n","# # Add the main report title and date\n","# story.append(Paragraph(\"OMENReport â€“ Strategy-Aligned Trades Summary\", title_style)) # Updated title\n","# story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","# story.append(Spacer(1, 12)) # Add some space\n","\n","# # Iterate through the df_strategy_trades DataFrame and add summary content to the story\n","# for index, row in df_strategy_trades.iterrows():\n","#     story.append(Paragraph(\"==========================================\", body_style))\n","#     story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","#     story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","#     story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style)) # Only include summary info\n","#     story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))     # Only include summary info\n","#     story.append(Paragraph(f\"- Sentiment: {row['Sentiment_summary']}\", body_style))\n","#     story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth_summary']}\", body_style))\n","#     story.append(Spacer(1, 12)) # Add space after each trade summary\n","\n","\n","# # Build the PDF document # Commented out PDF build\n","# try:\n","#     doc.build(story)\n","#     print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","#     # Download the PDF file\n","#     files.download(pdf_output_path)\n","\n","# except UnicodeEncodeError as e:\n","#     print(f\"UnicodeEncodeError encountered: {e}\")\n","#     print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","#     # Attempt to use DejaVuSans font if available\n","#     try:\n","#         # Define font paths - typically found in Colab\n","#         font_path = '/usr/share/fonts/truetype/dejavu/'\n","#         regular_font = font_path + 'DejaVuSans.ttf'\n","#         bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","#         # Check if font files exist before adding\n","#         if os.path.exists(regular_font) and os.path.exists(bold_font):\n","#             # Register the fonts\n","#             pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","#             pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","#             # Update styles to use DejaVuSans\n","#             styles['Normal'].fontName = 'DejaVuSans'\n","#             styles['h1'].fontName = 'DejaVuSans-Bold'\n","#             styles['h2'].fontName = 'DejaVuSans'\n","#             styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","#             styles['Normal'].leading = 14\n","#             styles['h3'].leading = 14\n","\n","\n","#             # Rebuild the document with the new font\n","#             doc.build(story)\n","#             print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","#             # Download the PDF file\n","#             files.download(pdf_output_path)\n","#         else:\n","#             print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","#     except Exception as font_error:\n","#         print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","#         print(\"PDF generation failed.\")\n","\n","# except Exception as other_error:\n","#     print(f\"An error occurred during PDF generation: {other_error}\")\n","#     print(\"PDF generation failed.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6432c978"},"outputs":[],"source":["# Re-create the strategy columns in the dataframe\n","import numpy as np\n","\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","# Display the first few rows with the new columns to confirm they are created\n","display(df[['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())\n","\n","# Now re-run the code to filter, generate AI summaries, populate story, build and download the PDF\n","# Re-run the filtering of strategy trades\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","df_strategy_trades = df[df[strategy_columns].any(axis=1)].copy()\n","\n","# Add 'Symbol' as 'Ticker' in df_strategy_trades before merging\n","df_strategy_trades['Ticker'] = df_strategy_trades['Symbol']\n","\n","# Define the columns to merge from summary\n","summary_cols_to_merge = ['Ticker', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']\n","\n","# Merge relevant columns from the summary DataFrame into df_strategy_trades,\n","# renaming Sentiment and Stealth to avoid conflict with existing columns\n","df_strategy_trades = df_strategy_trades.merge(\n","    summary[summary_cols_to_merge],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_trade', '_summary') # Add suffixes to distinguish columns\n",")\n","\n","# Drop duplicate rows that might be introduced by the merge if a ticker had multiple strategy trades\n","df_strategy_trades = df_strategy_trades.drop_duplicates(subset=['Ticker'])\n","\n","# # Re-generate and store AI summaries for strategy trades\n","# ai_summaries = []\n","# for index, row in df_strategy_trades.iterrows():\n","#     # Use a try-except block to catch potential API errors during the loop\n","#     try:\n","#         ai_text = ai_summary(\n","#             ticker=row['Ticker'],\n","#             premium=row['Max Premium'],\n","#             trade_type=row['Trade Type'],\n","#             strike_expiry=row['StrikeExpiry'],\n","#             sentiment=row['Sentiment_summary'],\n","#             stealth=row['Stealth_summary']\n","#         )\n","#         ai_summaries.append(ai_text)\n","#     except Exception as e:\n","#         print(f\"Error generating AI summary for {row['Ticker']}: {e}\")\n","#         ai_summaries.append(\"Error generating summary.\") # Append a placeholder\n","#         continue # Continue with the next iteration\n","\n","# # Assign the ai_summaries list as a new column named 'AI_Summary'\n","# df_strategy_trades['AI_Summary'] = ai_summaries\n","\n","# Populate the story list for the strategy trades report\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.lib.units import inch\n","from reportlab.pdfbase import pdfmetrics\n","from reportlab.pdfbase.ttfonts import TTFont\n","import os\n","from google.colab import files\n","\n","\n","# Define the output PDF file name\n","pdf_output_path = \"OMENReport_Strategy_Trades.pdf\"\n","\n","# Create a SimpleDocTemplate object with appropriate margins\n","doc = SimpleDocTemplate(\n","    pdf_output_path,\n","    pagesize=(8.27 * inch, 11.69 * inch), # A4 size\n","    leftMargin=0.75 * inch,\n","    rightMargin=0.75 * inch,\n","    topMargin=0.75 * inch,\n","    bottomMargin=0.75 * inch\n",")\n","\n","# Get a sample stylesheet\n","styles = getSampleStyleSheet()\n","\n","# Define styles for the title and body text\n","title_style = styles['h1']\n","title_style.alignment = 1 # Center alignment\n","body_style = styles['Normal']\n","body_style.leading = 14 # Adjust leading for better readability\n","bold_style = styles['h3'] # Using h3 for bold text for now\n","bold_style.leading = 14 # Adjust leading for better readability\n","\n","\n","# Create the story list and add the formatted content\n","story = []\n","\n","# Add the main report title and date\n","story.append(Paragraph(\"OMENReport â€“ Strategy-Aligned Trades Summary\", title_style)) # Updated title\n","story.append(Paragraph(f\"Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\", styles['h2']))\n","story.append(Spacer(1, 12)) # Add some space\n","\n","# Iterate through the df_strategy_trades DataFrame and add summary content to the story\n","for index, row in df_strategy_trades.iterrows():\n","    story.append(Paragraph(\"==========================================\", body_style))\n","    story.append(Paragraph(f\"ðŸ”¶ Ticker: {row['Ticker']}\", bold_style))\n","    story.append(Paragraph(f\"- Market Cap: {row['Market Cap']}\", body_style))\n","    story.append(Paragraph(f\"- Total Premium: ${row['Total Premium']:,.0f}\", body_style)) # Only include summary info\n","    story.append(Paragraph(f\"- Trade Count: {int(row['Trade Count'])}\", body_style))     # Only include summary info\n","    story.append(Paragraph(f\"- Sentiment: {row['Sentiment_summary']}\", body_style))\n","    story.append(Paragraph(f\"- Stealth Indicator: {row['Stealth_summary']}\", body_style))\n","    story.append(Spacer(1, 12)) # Add space after each trade summary\n","\n","\n","# Build the PDF document\n","try:\n","    doc.build(story)\n","    print(f\"âœ… PDF report generated: {pdf_output_path}\")\n","    # Download the PDF file\n","    files.download(pdf_output_path)\n","\n","except UnicodeEncodeError as e:\n","    print(f\"UnicodeEncodeError encountered: {e}\")\n","    print(\"Attempting to use a Unicode-friendly font like DejaVuSans.\")\n","\n","    # Attempt to use DejaVuSans font if available\n","    try:\n","        # Define font paths - typically found in Colab\n","        font_path = '/usr/share/fonts/truetype/dejavu/'\n","        regular_font = font_path + 'DejaVuSans.ttf'\n","        bold_font = font_path + 'DejaVuSans-Bold.ttf'\n","\n","        # Check if font files exist before adding\n","        if os.path.exists(regular_font) and os.path.exists(bold_font):\n","            # Register the fonts\n","            pdfmetrics.registerFont(TTFont('DejaVuSans', regular_font))\n","            pdfmetrics.registerFont(TTFont('DejaVuSans-Bold', bold_font))\n","\n","            # Update styles to use DejaVuSans\n","            styles['Normal'].fontName = 'DejaVuSans'\n","            styles['h1'].fontName = 'DejaVuSans-Bold'\n","            styles['h2'].fontName = 'DejaVuSans'\n","            styles['h3'].fontName = 'DejaVuSans-Bold' # For bold text\n","            styles['Normal'].leading = 14\n","            styles['h3'].leading = 14\n","\n","\n","            # Rebuild the document with the new font\n","            doc.build(story)\n","            print(f\"âœ… PDF report generated with DejaVuSans: {pdf_output_path}\")\n","            # Download the PDF file\n","            files.download(pdf_output_path)\n","        else:\n","            print(\"DejaVuSans font files not found. PDF generation failed due to Unicode characters.\")\n","\n","    except Exception as font_error:\n","        print(f\"Error attempting to use DejaVuSans font: {font_error}\")\n","        print(\"PDF generation failed.\")\n","\n","except Exception as other_error:\n","    print(f\"An error occurred during PDF generation: {other_error}\")\n","    print(\"PDF generation failed.\")"]},{"cell_type":"markdown","metadata":{"id":"95c99dd2"},"source":["# ## Create pdf document\n","\n","# ### Subtask:\n","# Initialize a PDF object using `FPDF`."]},{"cell_type":"markdown","metadata":{"id":"9aa64cea"},"source":["# **Reasoning**:\n","# Initialize a PDF object using FPDF."]},{"cell_type":"markdown","metadata":{"id":"4c1160be"},"source":["# ## Add content to pdf\n","\n","# ### Subtask:\n","# Add the report title, date, and iterate through the top trades (overall and small cap), adding each trade's details and the AI summary to the PDF with appropriate formatting (font, size, spacing)."]},{"cell_type":"markdown","metadata":{"id":"c7cb2068"},"source":["# **Reasoning**:\n","# Add a page to the PDF, set the font for the title, add the main report title, add the date, and then iterate through the top overall and small cap trades, adding their details and AI summaries to the PDF with appropriate formatting and spacing."]},{"cell_type":"markdown","metadata":{"id":"48a9dfc6"},"source":["# ## Import necessary modules from reportlab\n","\n","# ### Subtask:\n","# Import the required classes and functions from `reportlab.platypus` and `reportlab.lib.styles`."]},{"cell_type":"markdown","metadata":{"id":"37c4e1c9"},"source":["# ## Define pdf content structure\n","\n","# ### Subtask:\n","# Create a list of flowable objects (paragraphs, tables, etc.) that will represent the content of the PDF report."]},{"cell_type":"markdown","metadata":{"id":"d16e5f83"},"source":["# **Reasoning**:\n","# Initialize an empty list to store the flowable objects for the PDF content."]},{"cell_type":"markdown","metadata":{"id":"55033dd2"},"source":["# ## Populate pdf content\n","\n","# ### Subtask:\n","# Populate pdf content"]},{"cell_type":"markdown","metadata":{"id":"9480b501"},"source":["# **Reasoning**:\n","# Get a sample stylesheet, define styles for title and body text, add the main report title and date to the story, and iterate through the top overall trades, adding their details and AI summaries to the story list with appropriate formatting and spacing."]},{"cell_type":"markdown","metadata":{"id":"2175da69"},"source":["# **Reasoning**:\n","# Add a title for the \"Top 3 Small Cap Trades\" section and iterate through the top small cap trades, adding their details and AI summaries to the story list with appropriate formatting and spacing."]},{"cell_type":"markdown","metadata":{"id":"48619858"},"source":["# ## Build and save pdf\n","\n","# ### Subtask:\n","# Build and save pdf"]},{"cell_type":"markdown","metadata":{"id":"6f0d5ff6"},"source":["# **Reasoning**:\n","# Define the output path, create a SimpleDocTemplate object, and build the PDF document using the story list."]},{"cell_type":"markdown","metadata":{"id":"3db1956b"},"source":["# **Reasoning**:\n","# The PDF file has been built. Now, I need to provide a way for the user to download it."]},{"cell_type":"markdown","metadata":{"id":"d0dff2aa"},"source":["# ## Save and download pdf\n","\n","# ### Subtask:\n","# Save the generated PDF to a file and provide a download link."]},{"cell_type":"markdown","metadata":{"id":"daa8cab0"},"source":["# **Reasoning**:\n","# Define the output path, create a SimpleDocTemplate object, and build the PDF document using the story list. Then, provide a download link for the generated PDF."]},{"cell_type":"markdown","metadata":{"id":"9061e363"},"source":["# Task\n","Analyze the provided options trading data to identify the top 3 overall and top 3 small-cap trades based on a scoring system that prioritizes Strategy, then Unusual Option Activity Classes, and finally Premium Totals. Generate a TXT report of the identified top trades, including their details and AI summaries."]},{"cell_type":"markdown","metadata":{"id":"3c7dd7f2"},"source":["## Define unusual option activity criteria\n","\n","### Subtask:\n","Determine the specific criteria or patterns in your data that define \"unusual option activity.\" This might involve looking at trade size, premium, strike/expiry relative to current price and time, or other factors.\n"]},{"cell_type":"markdown","metadata":{"id":"9eaf5b4d"},"source":["**Reasoning**:\n","Based on the available columns and common indicators of unusual option activity, I will define three criteria: Large Premium, High Volume relative to Open Interest, and presence of specific flags/alerts (like Sweep or Repeater) combined with Above Ask sentiment. I will document these criteria in a markdown cell.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6642319"},"outputs":[],"source":["# Document the defined criteria for \"unusual option activity\"\n","\n","# Criteria for Unusual Option Activity:\n","\n","# 1. Large Premium:\n","#    Trades with a 'PremiumValue' significantly higher than average or above a certain threshold.\n","#    Reasoning: Large premiums often indicate strong conviction and potentially informed trading, as traders are willing to pay a high cost for the option.\n","\n","# 2. High Volume Relative to Open Interest (Vol > OI):\n","#    Trades where the 'Trade Size_numeric' is greater than the 'Open Interest_numeric' for that contract.\n","#    Reasoning: When volume significantly exceeds open interest, it suggests new positions are being opened rather than existing ones being closed, indicating strong current interest in that specific option.\n","\n","# 3. Aggressive Execution with Strategy Flags:\n","#    Trades marked with 'Sweep' or 'Repeater' flags that also have an 'Above Ask' trade spread.\n","#    Reasoning: Sweep and Repeater flags often signal aggressive institutional order execution. Combining this with an 'Above Ask' execution price further reinforces a sense of urgency and bullish conviction from the buyer.\n","\n","print(\"Defined criteria for Unusual Option Activity.\")"]},{"cell_type":"markdown","metadata":{"id":"ca365ad9"},"source":["## Implement unusual option activity identification\n","\n","### Subtask:\n","Add new code to your notebook to identify trades that meet the defined \"unusual option activity\" criteria and flag them in the DataFrame.\n"]},{"cell_type":"markdown","metadata":{"id":"196ec617"},"source":["**Reasoning**:\n","Define a threshold for \"Large Premium\" and create a new boolean column 'IsUnusual' based on the defined criteria, then display the head and the count of the filtered dataframe.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16983214"},"outputs":[],"source":["# 1. Define a threshold for \"Large Premium\"\n","# Using the 95th percentile of 'PremiumValue' as the threshold\n","large_premium_threshold = df['PremiumValue'].quantile(0.95)\n","print(f\"Large Premium Threshold (95th percentile): ${large_premium_threshold:,.2f}\")\n","\n","# 2. Create the 'IsUnusual' column based on the three criteria\n","df['IsUnusual'] = (\n","    (df['PremiumValue'] > large_premium_threshold) | # Criterion 1: Large Premium\n","    (df['Vol > OI']) | # Criterion 2: Volume > Open Interest (already calculated)\n","    ((df['Sweep'] | df['Repeater']) & df['Above Ask']) # Criterion 3: Aggressive Execution with Strategy Flags\n",")\n","\n","# 3. Display the first few rows of the DataFrame with the new column and the count of unusual trades\n","display(df[['PremiumValue', 'Trade Size_numeric', 'Open Interest_numeric', 'Sweep', 'Repeater', 'Above Ask', 'Vol > OI', 'IsUnusual']].head())\n","print(f\"Number of trades flagged as unusual: {df['IsUnusual'].sum()}\")"]},{"cell_type":"markdown","metadata":{"id":"c8fe3e10"},"source":["## Define and implement scoring system\n","\n","### Subtask:\n","Create a scoring system based on Sentiment, Stealth, and the identified Unusual Option Activity Classes. This will likely involve assigning points or weights to different categories within these criteria.\n"]},{"cell_type":"markdown","metadata":{"id":"e1ab0f90"},"source":["**Reasoning**:\n","Define a function to calculate a score based on sentiment, stealth, and unusual activity, and then apply it to the DataFrame to create the 'Score' column. Finally, display the relevant columns to verify the result.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ca92b5b"},"outputs":[],"source":["def calculate_score(row):\n","    \"\"\"Calculates a trade score based on sentiment, stealth, and unusual activity.\"\"\"\n","    score = 0\n","\n","    # Score based on Sentiment (example weighting)\n","    if row['Sentiment'] == 'Aggressive Bullish' or row['Sentiment'] == 'Aggressive Bearish':\n","        score += 5\n","    elif row['Sentiment'] == 'Bullish' or row['Sentiment'] == 'Bearish':\n","        score += 3\n","    else: # Neutral\n","        score += 1\n","\n","    # Score based on Stealth\n","    if row['Stealth'] == 'âœ… High Stealth':\n","        score += 4\n","    else: # âŒ None\n","        score += 1\n","\n","    # Score based on Unusual Activity\n","    if row['IsUnusual']:\n","        score += 5\n","    else:\n","        score += 1 # Even non-unusual trades get a base score\n","\n","\n","    return score\n","\n","# Apply the function to create the 'Score' column\n","df['Score'] = df.apply(calculate_score, axis=1)\n","\n","# Display the first few rows with the relevant columns\n","display(df[['Symbol', 'Sentiment', 'Stealth', 'IsUnusual', 'Score']].head())"]},{"cell_type":"markdown","metadata":{"id":"0b47f885"},"source":["## Identify top trades based on score and premium\n","\n","### Subtask:\n","Modify the code to calculate the score for each trade and then identify the top 3 overall and top 3 small cap trades based on this score, potentially using premium totals as a secondary ranking factor.\n"]},{"cell_type":"markdown","metadata":{"id":"5a5674c1"},"source":["**Reasoning**:\n","Sort the DataFrame by 'Score' and 'PremiumValue', then select the top 3 overall and top 3 small cap trades based on this sorting, and display the results.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5878ba0"},"outputs":[],"source":["# Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False])\n","\n","# Select the top 3 overall trades\n","top3_overall_scored = df_sorted.head(3)\n","\n","# Filter for Small Cap trades and select the top 3\n","small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap']\n","top3_small_cap_scored = small_cap_df_sorted.head(3)\n","\n","# Display the resulting DataFrames\n","print(\"Top 3 Overall Trades (Scored):\")\n","display(top3_overall_scored[['Symbol', 'Score', 'PremiumValue', 'Sentiment', 'Stealth', 'IsUnusual']])\n","\n","print(\"\\nTop 3 Small Cap Trades (Scored):\")\n","display(top3_small_cap_scored[['Symbol', 'Score', 'PremiumValue', 'Sentiment', 'Stealth', 'IsUnusual', 'Market Cap']])"]},{"cell_type":"markdown","metadata":{"id":"ee30f99d"},"source":["**Reasoning**:\n","The previous command failed because the 'Market Cap' column is not present in the `df_sorted` DataFrame. The 'Market Cap' column was created and added to the `summary` DataFrame earlier but was not merged back into the main `df` DataFrame. I need to merge the 'Market Cap' information from the `summary` DataFrame into the main `df` DataFrame before attempting to filter by it.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tG_Ka64viCKt"},"outputs":[],"source":["# Merge the 'Market Cap' column from the summary DataFrame into the main df DataFrame\n","df = df.merge(summary[['Ticker', 'Market Cap']], on='Ticker', how='left')\n","\n","# Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False])\n","\n","# Select the top 3 overall trades\n","top3_overall_scored = df_sorted.head(3)\n","\n","# Filter for Small Cap trades and select the top 3\n","small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap']\n","top3_small_cap_scored = small_cap_df_sorted.head(3)\n","\n","# Display the resulting DataFrames\n","print(\"Top 3 Overall Trades (Scored):\")\n","display(top3_overall_scored[['Symbol', 'Score', 'PremiumValue', 'Sentiment', 'Stealth', 'IsUnusual', 'Market Cap']])\n","\n","print(\"\\nTop 3 Small Cap Trades (Scored):\")\n","display(top3_small_cap_scored[['Symbol', 'Score', 'PremiumValue', 'Sentiment', 'Stealth', 'IsUnusual', 'Market Cap']])"]},{"cell_type":"markdown","metadata":{"id":"eeeaadab"},"source":["**Reasoning**:\n","The previous command failed because the main `df` DataFrame does not have a 'Ticker' column to merge on. The 'Symbol' column in `df` corresponds to the 'Ticker' in the `summary` DataFrame. I need to rename the 'Symbol' column in `df` to 'Ticker' before performing the merge to correctly bring in the 'Market Cap' information.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQNrZ9_wiD5p"},"outputs":[],"source":["# Rename the 'Symbol' column to 'Ticker' in the main df DataFrame for merging\n","df = df.rename(columns={'Symbol': 'Ticker'})\n","\n","# Merge the 'Market Cap' column from the summary DataFrame into the main df DataFrame\n","df = df.merge(summary[['Ticker', 'Market Cap']], on='Ticker', how='left')\n","\n","# Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False])\n","\n","# Select the top 3 overall trades\n","top3_overall_scored = df_sorted.head(3)\n","\n","# Filter for Small Cap trades and select the top 3\n","small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap']\n","top3_small_cap_scored = small_cap_df_sorted.head(3)\n","\n","# Display the resulting DataFrames\n","print(\"Top 3 Overall Trades (Scored):\")\n","display(top3_overall_scored[['Ticker', 'Score', 'PremiumValue', 'Sentiment', 'Stealth', 'IsUnusual', 'Market Cap']])\n","\n","print(\"\\nTop 3 Small Cap Trades (Scored):\")\n","display(top3_small_cap_scored[['Ticker', 'Score', 'PremiumValue', 'Sentiment', 'Stealth', 'IsUnusual', 'Market Cap']])"]},{"cell_type":"markdown","metadata":{"id":"0373252a"},"source":["## Generate and save updated txt report\n","\n","### Subtask:\n","Generate the TXT report for the newly identified top trades, including their details, the criteria that contributed to their score, and their AI summaries.\n"]},{"cell_type":"markdown","metadata":{"id":"76416814"},"source":["**Reasoning**:\n","Define a function `format_scored_omen_template` to format the report content, call this function for the top overall and small cap scored trades, and then write the formatted content to a text file and provide a download link.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ac147b41"},"outputs":[],"source":["def format_scored_omen_template(df, title):\n","    \"\"\"Formats scored trade data and AI summaries into a string for the TXT report.\"\"\"\n","    report = f\"\\nðŸš€ OMENReport â€“ {title}\\n\\n\"\n","    report += f\"ðŸ“… Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\"\n","\n","    for _, row in df.iterrows():\n","        report += \"==========================================\\n\"\n","        report += f\"ðŸ”¶ Ticker: {row['Ticker']}\\n\"\n","        report += f\"- Market Cap: {row['Market Cap']}\\n\"\n","        report += f\"- Score: {row['Score']}\\n\" # Include the score\n","        report += f\"- Trade Type: {row['Trade Type']}\\n\"\n","        report += f\"- Strike/Expiry: {row['StrikeExpiry']}\\n\"\n","        report += f\"- Premium Size (Max Trade): ${row['Max Premium']:,.0f}\\n\" # Use Max Premium from summary\n","        report += f\"- Total Premium: ${row['Total Premium']:,.0f}\\n\" # Use Total Premium from summary\n","        report += f\"- Trade Count: {int(row['Trade Count'])}\\n\" # Use Trade Count from summary\n","        report += f\"- Sentiment: {row['Sentiment_summary']}\\n\" # Use Sentiment from summary merge\n","        report += f\"- Stealth Indicator: {row['Stealth_summary']}\\n\" # Use Stealth from summary merge\n","        report += \"- Strategy Criteria Met:\\n\" # Indicate strategy criteria\n","        strategy_criteria = {\n","            'Sweep': row['Sweep'],\n","            'Above Ask': row['Above Ask'],\n","            'Vol > OI': row['Vol > OI'],\n","            'Repeater': row['Repeater'],\n","            'Odd Lot': row['Odd Lot'],\n","            'Short Dated': row['Short Dated']\n","        }\n","        for criteria, met in strategy_criteria.items():\n","            if met:\n","                report += f\"  - {criteria}\\n\"\n","        report += \"\\n\"\n","\n","        report += \"ðŸ§  AI Summary:\\n\"\n","        # Check if AI_Summary column exists before accessing\n","        if 'AI_Summary' in row and pd.notna(row['AI_Summary']):\n","             report += f\"{row['AI_Summary']}\\n\"\n","        else:\n","             # If AI summary is not pre-generated, generate it now (potentially slow)\n","             try:\n","                ai_text = ai_summary(\n","                    ticker=row['Ticker'],\n","                    premium=row['Max Premium'],\n","                    trade_type=row['Trade Type'],\n","                    strike_expiry=row['StrikeExpiry'],\n","                    sentiment=row['Sentiment_summary'],\n","                    stealth=row['Stealth_summary']\n","                )\n","                report += f\"{ai_text}\\n\"\n","             except Exception as e:\n","                 report += f\"Error generating AI summary: {e}\\n\"\n","        report += \"==========================================\\n\\n\"\n","\n","    return report\n","\n","# Call the formatting function for the top 3 overall scored trades\n","top3_overall_report = format_scored_omen_template(top3_overall_scored, \"Top 3 Overall Scored Trades\")\n","\n","# Call the formatting function for the top 3 small cap scored trades\n","top3_small_cap_report = format_scored_omen_template(top3_small_cap_scored, \"Top 3 Small Cap Scored Trades\")\n","\n","# Print the reports\n","print(top3_overall_report)\n","print(top3_small_cap_report)\n","\n","# Save the reports to a TXT file\n","output_filename = \"OMENReport_Scored_AI.txt\"\n","with open(output_filename, \"w\") as file:\n","    file.write(top3_overall_report)\n","    file.write(top3_small_cap_report)\n","\n","print(f\"âœ… Report saved to {output_filename}\")\n","\n","# Provide a download link\n","files.download(output_filename)"]},{"cell_type":"markdown","metadata":{"id":"0a538f60"},"source":["**Reasoning**:\n","The previous command failed because the `top3_overall_scored` and `top3_small_cap_scored` DataFrames do not contain the 'Max Premium', 'Total Premium', and 'Trade Count' columns required by the `format_scored_omen_template` function. These columns are present in the original `summary` DataFrame. I need to merge these columns from the `summary` DataFrame into the `top3_overall_scored` and `top3_small_cap_scored` DataFrames before calling the formatting function.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0QGxQiOiK4H"},"outputs":[],"source":["# Merge relevant columns from the summary DataFrame into top3_overall_scored\n","top3_overall_scored = top3_overall_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Merge relevant columns from the summary DataFrame into top3_small_cap_scored\n","top3_small_cap_scored = top3_small_cap_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Define a function to format the scored trade data and AI summaries\n","def format_scored_omen_template(df, title):\n","    \"\"\"Formats scored trade data and AI summaries into a string for the TXT report.\"\"\"\n","    report = f\"\\nðŸš€ OMENReport â€“ {title}\\n\\n\"\n","    report += f\"ðŸ“… Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\"\n","\n","    for _, row in df.iterrows():\n","        report += \"==========================================\\n\"\n","        report += f\"ðŸ”¶ Ticker: {row['Ticker']}\\n\"\n","        report += f\"- Market Cap: {row['Market Cap']}\\n\"\n","        report += f\"- Score: {row['Score']}\\n\" # Include the score\n","        report += f\"- Trade Type: {row['Trade Type']}\\n\"\n","        report += f\"- Strike/Expiry: {row['StrikeExpiry']}\\n\"\n","        report += f\"- Premium Size (Max Trade): ${row['Max Premium']:,.0f}\\n\" # Use Max Premium from summary merge\n","        report += f\"- Total Premium: ${row['Total Premium']:,.0f}\\n\" # Use Total Premium from summary merge\n","        report += f\"- Trade Count: {int(row['Trade Count'])}\\n\" # Use Trade Count from summary merge\n","        report += f\"- Sentiment: {row['Sentiment_summary']}\\n\" # Use Sentiment from summary merge\n","        report += f\"- Stealth Indicator: {row['Stealth_summary']}\\n\" # Use Stealth from summary merge\n","        report += \"- Strategy Criteria Met:\\n\" # Indicate strategy criteria\n","        strategy_criteria = {\n","            'Sweep': row['Sweep'],\n","            'Above Ask': row['Above Ask'],\n","            'Vol > OI': row['Vol > OI'],\n","            'Repeater': row['Repeater'],\n","            'Odd Lot': row['Odd Lot'],\n","            'Short Dated': row['Short Dated']\n","        }\n","        for criteria, met in strategy_criteria.items():\n","            if met:\n","                report += f\"  - {criteria}\\n\"\n","        report += \"\\n\"\n","\n","        report += \"ðŸ§  AI Summary:\\n\"\n","        # Check if AI_Summary column exists before accessing\n","        if 'AI_Summary' in row and pd.notna(row['AI_Summary']):\n","             report += f\"{row['AI_Summary']}\\n\"\n","        else:\n","             # If AI summary is not pre-generated, generate it now (potentially slow)\n","             try:\n","                ai_text = ai_summary(\n","                    ticker=row['Ticker'],\n","                    premium=row['Max Premium'],\n","                    trade_type=row['Trade Type'],\n","                    strike_expiry=row['StrikeExpiry'],\n","                    sentiment=row['Sentiment_summary'],\n","                    stealth=row['Stealth_summary']\n","                )\n","                report += f\"{ai_text}\\n\"\n","             except Exception as e:\n","                 report += f\"Error generating AI summary: {e}\\n\"\n","        report += \"==========================================\\n\\n\"\n","\n","    return report\n","\n","# Call the formatting function for the top 3 overall scored trades\n","top3_overall_report = format_scored_omen_template(top3_overall_scored, \"Top 3 Overall Scored Trades\")\n","\n","# Call the formatting function for the top 3 small cap scored trades\n","top3_small_cap_report = format_scored_omen_template(top3_small_cap_scored, \"Top 3 Small Cap Scored Trades\")\n","\n","# Print the reports\n","print(top3_overall_report)\n","print(top3_small_cap_report)\n","\n","# Save the reports to a TXT file\n","output_filename = \"OMENReport_Scored_AI.txt\"\n","with open(output_filename, \"w\") as file:\n","    file.write(top3_overall_report)\n","    file.write(top3_small_cap_report)\n","\n","print(f\"âœ… Report saved to {output_filename}\")\n","\n","# Provide a download link\n","files.download(output_filename)"]},{"cell_type":"markdown","metadata":{"id":"724250a5"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   Three criteria were defined for \"unusual option activity\": trades with a 'PremiumValue' greater than the 95th percentile (\\$532,034), trades where volume exceeds open interest, and trades marked with 'Sweep' or 'Repeater' flags combined with an 'Above Ask' execution.\n","*   A total of 832 trades were identified as unusual based on the defined criteria.\n","*   A scoring system was successfully implemented, assigning points based on Sentiment (higher for aggressive sentiment), Stealth (higher for high stealth), and Unusual Activity (higher for unusual trades).\n","*   The top 3 overall trades were identified by sorting the data primarily by 'Score' and secondarily by 'PremiumValue' in descending order.\n","*   The top 3 small-cap trades were identified by filtering for 'Small Cap' trades and then applying the same sorting logic.\n","*   A TXT report was generated containing details for the top 3 overall and top 3 small-cap scored trades, including their score, premium details, sentiment, stealth, contributing strategy criteria, and an AI-generated summary.\n","\n","### Insights or Next Steps\n","\n","*   Analyze the characteristics of the top-scoring trades to refine the scoring system and identify common patterns among high-conviction trades.\n","*   Integrate real-time data feeds to apply the scoring system and identify top trades as they occur, enabling more timely trading decisions.\n"]},{"cell_type":"markdown","metadata":{"id":"84488093"},"source":["# Task\n","Analyze the provided stock data, prioritizing strategy criteria, then unusual option activity classes, and finally premium totals to identify the top 3 overall and small-cap stocks. Generate a text report summarizing the findings using the Gemini API."]},{"cell_type":"markdown","metadata":{"id":"aebca94a"},"source":["## Install google generative ai library\n","\n","### Subtask:\n","Add a step to install the `google-generativeai` library.\n"]},{"cell_type":"markdown","metadata":{"id":"e5f03414"},"source":["**Reasoning**:\n","The subtask is to install the `google-generativeai` library. I will use the `pip install` command within a code block to accomplish this.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5adb84f2"},"outputs":[],"source":["!pip install google-generativeai"]},{"cell_type":"markdown","metadata":{"id":"66a1a529"},"source":["## Import google generative ai modules\n","\n","### Subtask:\n","Import the necessary modules from the installed library.\n"]},{"cell_type":"markdown","metadata":{"id":"51dff200"},"source":["**Reasoning**:\n","Import the necessary components from the `google.generativeai` library to interact with the Gemini API.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"14756ec6"},"outputs":[],"source":["import google.generativeai as genai\n","from google.colab import userdata\n","\n","# Configure the API key\n","GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)\n","\n","print(\"Gemini API key configured.\")"]},{"cell_type":"markdown","metadata":{"id":"72df6c80"},"source":["## Configure gemini api\n","\n","### Subtask:\n","Set up the Gemini API key, similar to how the OpenAI key is handled.\n"]},{"cell_type":"markdown","metadata":{"id":"01c54333"},"source":["**Reasoning**:\n","Set up the Gemini API key by importing necessary modules and configuring the library with the key from Colab Secrets.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74393045"},"outputs":[],"source":["!pip install google-generativeai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"120a6eca"},"outputs":[],"source":["import google.generativeai as genai\n","from google.colab import userdata\n","\n","# Configure the API key\n","GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)\n","\n","print(\"Gemini API key configured.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"721bcc15"},"outputs":[],"source":["# Sample data for testing the ai_summary function with Gemini\n","test_ticker = \"AAPL\"\n","test_premium = 150000.0\n","test_trade_type = \"Sweep\"\n","test_strike_expiry = \"180 Call - 07/19/2024\"\n","test_sentiment = \"Bullish\"\n","test_stealth = \"âœ… High Stealth\"\n","\n","# Call the ai_summary function with the test data\n","test_summary = ai_summary(\n","    ticker=test_ticker,\n","    premium=test_premium,\n","    trade_type=test_trade_type,\n","    strike_expiry=test_strike_expiry,\n","    sentiment=test_sentiment,\n","    stealth=test_stealth\n",")\n","\n","# Print the generated summary\n","print(\"Test AI Summary from Gemini:\")\n","print(test_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7411e3d"},"outputs":[],"source":["# Re-create the strategy columns in the dataframe\n","import numpy as np\n","\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","# Display the first few rows with the new columns to confirm they are created\n","display(df[['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())\n","\n","# Now calculate the 'IsUnusual' column based on the defined criteria\n","# 1. Define a threshold for \"Large Premium\" (using the 95th percentile of 'PremiumValue')\n","large_premium_threshold = df['PremiumValue'].quantile(0.95)\n","print(f\"\\nLarge Premium Threshold (95th percentile): ${large_premium_threshold:,.2f}\")\n","\n","# 2. Create the 'IsUnusual' column based on the three criteria\n","df['IsUnusual'] = (\n","    (df['PremiumValue'] > large_premium_threshold) | # Criterion 1: Large Premium\n","    (df['Vol > OI']) | # Criterion 2: Volume > Open Interest (already calculated)\n","    ((df['Sweep'] | df['Repeater']) & df['Above Ask']) # Criterion 3: Aggressive Execution with Strategy Flags\n",")\n","print(f\"Number of trades flagged as unusual: {df['IsUnusual'].sum()}\")\n","\n","# Now calculate the 'Score' for each trade\n","def calculate_score(row):\n","    \"\"\"Calculates a trade score based on sentiment, stealth, and unusual activity.\"\"\"\n","    score = 0\n","\n","    # Score based on Sentiment (example weighting)\n","    if row['Sentiment'] == 'Aggressive Bullish' or row['Sentiment'] == 'Aggressive Bearish':\n","        score += 5\n","    elif row['Sentiment'] == 'Bullish' or row['Sentiment'] == 'Bearish':\n","        score += 3\n","    else: # Neutral\n","        score += 1\n","\n","    # Score based on Stealth\n","    if row['Stealth'] == 'âœ… High Stealth':\n","        score += 4\n","    else: # âŒ None\n","        score += 1\n","\n","    # Score based on Unusual Activity\n","    if row['IsUnusual']:\n","        score += 5\n","    else:\n","        score += 1 # Even non-unusual trades get a base score\n","\n","    return score\n","\n","# Apply the function to create the 'Score' column\n","df['Score'] = df.apply(calculate_score, axis=1)\n","\n","# Display the first few rows with the relevant columns to verify the scoring\n","display(df[['Ticker', 'Sentiment', 'Stealth', 'IsUnusual', 'Score']].head())\n","\n","\n","# Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False]).copy() # Use .copy() to avoid SettingWithCopyWarning\n","\n","# Select the top 3 overall trades\n","top3_overall_scored = df_sorted.head(3).copy() # Use .copy()\n","\n","# Filter for Small Cap trades and select the top 3\n","small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap'].copy() # Use .copy()\n","top3_small_cap_scored = small_cap_df_sorted.head(3).copy() # Use .copy()\n","\n","# Merge relevant columns from the summary DataFrame into top3_overall_scored\n","top3_overall_scored = top3_overall_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Merge relevant columns from the summary DataFrame into top3_small_cap_scored\n","top3_small_cap_scored = top3_small_cap_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Define a function to format the scored trade data and AI summaries for TXT\n","def format_scored_omen_template_txt(df, title, strategy_columns):\n","    \"\"\"Formats scored trade data and AI summaries into a string for the TXT report.\"\"\"\n","    report = f\"\\nðŸš€ OMENReport â€“ {title}\\n\\n\"\n","    report += f\"ðŸ“… Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\"\n","\n","    for _, row in df.iterrows():\n","        report += \"==========================================\\n\"\n","        report += f\"ðŸ”¶ Ticker: {row['Ticker']}\\n\"\n","        report += f\"- Market Cap: {row['Market Cap']}\\n\"\n","        report += f\"- Score: {row['Score']}\\n\" # Include the score\n","        report += f\"- Trade Type: {row['Trade Type']}\\n\"\n","        report += f\"- Strike/Expiry: {row['StrikeExpiry']}\\n\"\n","        report += f\"- Premium Size (Max Trade): ${row['Max Premium']:,.0f}\\n\" # Use Max Premium from summary merge\n","        report += f\"- Total Premium: ${row['Total Premium']:,.0f}\\n\" # Use Total Premium from summary merge\n","        report += f\"- Trade Count: {int(row['Trade Count'])}\\n\" # Use Trade Count from summary merge\n","        report += f\"- Sentiment: {row['Sentiment_summary']}\\n\" # Use Sentiment from summary merge\n","        report += f\"- Stealth Indicator: {row['Stealth_summary']}\\n\" # Use Stealth from summary merge\n","        report += \"\\n\"\n","\n","        # Add strategy criteria details\n","        report += \"Strategy Criteria Met:\\n\"\n","        for col in strategy_columns:\n","            status = \"âœ… Yes\" if row[col] else \"âŒ No\"\n","            report += f\"  - {col}: {status}\\n\"\n","        report += \"\\n\"\n","\n","        report += \"ðŸ§  AI Summary:\\n\"\n","        # Generate AI summary using the Gemini-powered function\n","        try:\n","            ai_text = ai_summary(\n","                ticker=row['Ticker'],\n","                premium=row['Max Premium'],\n","                trade_type=row['Trade Type'],\n","                strike_expiry=row['StrikeExpiry'],\n","                sentiment=row['Sentiment_summary'],\n","                stealth=row['Stealth_summary']\n","            )\n","            report += f\"{ai_text}\\n\"\n","        except Exception as e:\n","             report += f\"Error generating AI summary with Gemini: {e}\\n\"\n","\n","        report += \"==========================================\\n\\n\"\n","\n","    return report\n","\n","# Define the strategy columns used for criteria\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","\n","\n","# Call the formatting function for the top 3 overall scored trades\n","top3_overall_report = format_scored_omen_template_txt(top3_overall_scored, \"Top 3 Overall Scored Trades\", strategy_columns)\n","\n","# Call the formatting function for the top 3 small cap scored trades\n","top3_small_cap_report = format_scored_omen_template_txt(top3_small_cap_scored, \"Top 3 Small Cap Scored Trades\", strategy_columns)\n","\n","# Print the reports\n","print(top3_overall_report)\n","print(top3_small_cap_report)\n","\n","# Save the reports to a TXT file\n","output_filename = \"OMENReport_Scored_AI.txt\"\n","with open(output_filename, \"w\") as file:\n","    file.write(top3_overall_report)\n","    file.write(top3_small_cap_report)\n","\n","print(f\"âœ… Report saved to {output_filename}\")\n","\n","# Provide a download link\n","files.download(output_filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"70a2b1f7"},"outputs":[],"source":["# Run the cell again after ensuring the secret is added\n","import google.generativeai as genai\n","from google.colab import userdata\n","\n","try:\n","    # Configure the API key\n","    GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')\n","    genai.configure(api_key=GOOGLE_API_KEY)\n","\n","    print(\"Gemini API key configured successfully.\")\n","\n","except Exception as e:\n","    print(f\"Error configuring Gemini API: {e}\")\n","    print(\"Please ensure you have added your GEMINI_API_KEY to Colab Secrets.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4b3fdda"},"outputs":[],"source":["# Re-create the strategy columns in the dataframe\n","import numpy as np\n","\n","# 1. Sweep Orders\n","df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","# 2. Above Ask\n","df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","# 3. Volume > Open Interest\n","# Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","def clean_numeric_column(col):\n","    col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","    return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","# 4. Repeater Orders\n","df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","# 5. Odd Lots\n","# Simple check: not a multiple of 100 for Trade Size > 0\n","df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","# 6. Short-Dated Contracts\n","# Convert 'Expiration Date' to datetime, handling errors\n","df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","# Define short-dated as less than 30 days from the current date\n","current_date = pd.Timestamp.now()\n","df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","# Display the first few rows with the new columns to confirm they are created\n","display(df[['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())\n","\n","# Now calculate the 'IsUnusual' column based on the defined criteria\n","# 1. Define a threshold for \"Large Premium\" (using the 95th percentile of 'PremiumValue')\n","large_premium_threshold = df['PremiumValue'].quantile(0.95)\n","print(f\"\\nLarge Premium Threshold (95th percentile): ${large_premium_threshold:,.2f}\")\n","\n","# 2. Create the 'IsUnusual' column based on the three criteria\n","df['IsUnusual'] = (\n","    (df['PremiumValue'] > large_premium_threshold) | # Criterion 1: Large Premium\n","    (df['Vol > OI']) | # Criterion 2: Volume > Open Interest (already calculated)\n","    ((df['Sweep'] | df['Repeater']) & df['Above Ask']) # Criterion 3: Aggressive Execution with Strategy Flags\n",")\n","print(f\"Number of trades flagged as unusual: {df['IsUnusual'].sum()}\")\n","\n","# Now calculate the 'Score' for each trade\n","def calculate_score(row):\n","    \"\"\"Calculates a trade score based on sentiment, stealth, and unusual activity.\"\"\"\n","    score = 0\n","\n","    # Score based on Sentiment (example weighting)\n","    if row['Sentiment'] == 'Aggressive Bullish' or row['Sentiment'] == 'Aggressive Bearish':\n","        score += 5\n","    elif row['Sentiment'] == 'Bullish' or row['Sentiment'] == 'Bearish':\n","        score += 3\n","    else: # Neutral\n","        score += 1\n","\n","    # Score based on Stealth\n","    if row['Stealth'] == 'âœ… High Stealth':\n","        score += 4\n","    else: # âŒ None\n","        score += 1\n","\n","    # Score based on Unusual Activity\n","    if row['IsUnusual']:\n","        score += 5\n","    else:\n","        score += 1 # Even non-unusual trades get a base score\n","\n","    return score\n","\n","# Apply the function to create the 'Score' column\n","df['Score'] = df.apply(calculate_score, axis=1)\n","\n","# Display the first few rows with the relevant columns to verify the scoring\n","display(df[['Ticker', 'Sentiment', 'Stealth', 'IsUnusual', 'Score']].head())\n","\n","\n","# Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False]).copy() # Use .copy() to avoid SettingWithCopyWarning\n","\n","# Select the top 3 overall trades\n","top3_overall_scored = df_sorted.head(3).copy() # Use .copy()\n","\n","# Filter for Small Cap trades and select the top 3\n","small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap'].copy() # Use .copy()\n","top3_small_cap_scored = small_cap_df_sorted.head(3).copy() # Use .copy()\n","\n","# Merge relevant columns from the summary DataFrame into top3_overall_scored\n","top3_overall_scored = top3_overall_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Merge relevant columns from the summary DataFrame into top3_small_cap_scored\n","top3_small_cap_scored = top3_small_cap_scored.merge(\n","    summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","    on='Ticker',\n","    how='left',\n","    suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n",")\n","\n","# Define a function to format the scored trade data and AI summaries for TXT\n","def format_scored_omen_template_txt(df, title, strategy_columns):\n","    \"\"\"Formats scored trade data and AI summaries into a string for the TXT report.\"\"\"\n","    report = f\"\\nðŸš€ OMENReport â€“ {title}\\n\\n\"\n","    report += f\"ðŸ“… Date: {pd.Timestamp.now().strftime('%B %d, %Y')}\\n\\n\"\n","\n","    for _, row in df.iterrows():\n","        report += \"==========================================\\n\"\n","        report += f\"ðŸ”¶ Ticker: {row['Ticker']}\\n\"\n","        report += f\"- Market Cap: {row['Market Cap']}\\n\"\n","        report += f\"- Score: {row['Score']}\\n\" # Include the score\n","        report += f\"- Trade Type: {row['Trade Type']}\\n\"\n","        report += f\"- Strike/Expiry: {row['StrikeExpiry']}\\n\"\n","        report += f\"- Premium Size (Max Trade): ${row['Max Premium']:,.0f}\\n\" # Use Max Premium from summary merge\n","        report += f\"- Total Premium: ${row['Total Premium']:,.0f}\\n\" # Use Total Premium from summary merge\n","        report += f\"- Trade Count: {int(row['Trade Count'])}\\n\" # Use Trade Count from summary merge\n","        report += f\"- Sentiment: {row['Sentiment_summary']}\\n\" # Use Sentiment from summary merge\n","        report += f\"- Stealth Indicator: {row['Stealth_summary']}\\n\" # Use Stealth from summary merge\n","        report += \"\\n\"\n","\n","        # Add strategy criteria details\n","        report += \"Strategy Criteria Met:\\n\"\n","        for col in strategy_columns:\n","            status = \"âœ… Yes\" if row[col] else \"âŒ No\"\n","            report += f\"  - {col}: {status}\\n\"\n","        report += \"\\n\"\n","\n","        report += \"ðŸ§  AI Summary:\\n\"\n","        # Generate AI summary using the Gemini-powered function\n","        try:\n","            ai_text = ai_summary(\n","                ticker=row['Ticker'],\n","                premium=row['Max Premium'],\n","                trade_type=row['Trade Type'],\n","                strike_expiry=row['StrikeExpiry'],\n","                sentiment=row['Sentiment_summary'],\n","                stealth=row['Stealth_summary']\n","            )\n","            report += f\"{ai_text}\\n\"\n","        except Exception as e:\n","             report += f\"Error generating AI summary with Gemini: {e}\\n\"\n","\n","        report += \"==========================================\\n\\n\"\n","\n","    return report\n","\n","# Define the strategy columns used for criteria\n","strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","\n","\n","# Call the formatting function for the top 3 overall scored trades\n","top3_overall_report = format_scored_omen_template_txt(top3_overall_scored, \"Top 3 Overall Scored Trades\", strategy_columns)\n","\n","# Call the formatting function for the top 3 small cap scored trades\n","top3_small_cap_report = format_scored_omen_template_txt(top3_small_cap_scored, \"Top 3 Small Cap Scored Trades\", strategy_columns)\n","\n","# Print the reports\n","print(top3_overall_report)\n","print(top3_small_cap_report)\n","\n","# Save the reports to a TXT file\n","output_filename = \"OMENReport_Scored_AI.txt\"\n","with open(output_filename, \"w\") as file:\n","    file.write(top3_overall_report)\n","    file.write(top3_small_cap_report)\n","\n","print(f\"âœ… Report saved to {output_filename}\")\n","\n","# Provide a download link\n","files.download(output_filename)"]},{"cell_type":"markdown","metadata":{"id":"ef08630a"},"source":["# Task\n","Convert the provided Colab notebook code into a Streamlit web application. The application should include a file uploader for a Spider Scanner CSV, a button to initiate the scan and report generation, a display area for the generated OMENReport, and a download button to export the report as a .txt file. The existing data processing logic from the notebook should be preserved. Provide the complete Streamlit code (`app.py`) and a `requirements.txt` file."]},{"cell_type":"markdown","metadata":{"id":"4f640056"},"source":["## Create `requirements.txt`\n","\n","### Subtask:\n","Generate a `requirements.txt` file containing the necessary libraries for the Streamlit app.\n"]},{"cell_type":"markdown","metadata":{"id":"041a7701"},"source":["**Reasoning**:\n","I need to identify the required libraries from the provided notebook code and create a `requirements.txt` file. I will list the necessary libraries, including streamlit, in the file.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1751225334187,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"10475d55","outputId":"b9bc2ea7-fec6-4a65-8324-9e9c8ff7859d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing requirements.txt\n"]}],"source":["%%writefile requirements.txt\n","pandas\n","matplotlib\n","openpyxl\n","fpdf2\n","openai\n","google-generativeai\n","streamlit"]},{"cell_type":"markdown","metadata":{"id":"11b9ebda"},"source":["## Structure the streamlit app\n","\n","### Subtask:\n","Create a new Python file (`app.py`) and import the required libraries, including Streamlit.\n"]},{"cell_type":"markdown","metadata":{"id":"c995e0d5"},"source":["**Reasoning**:\n","Create a new Python file named `app.py` and add the necessary import statements for Streamlit and other libraries used in the original notebook.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1751225346458,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"1162d8b0","outputId":"08050edf-ed5e-4d7a-a421-1ceeeaad7bd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from fpdf import FPDF\n","import openai\n","import os\n","import google.generativeai as genai\n","import numpy as np\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{"id":"465ec069"},"source":["**Reasoning**:\n","The `app.py` file has been created with the initial imports. Now I need to incorporate the API key handling logic from the notebook into the Streamlit app.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"elapsed":265,"status":"error","timestamp":1751225354329,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"1670321f","outputId":"f95eb211-8d3d-4a61-fbad-87c940704432"},"outputs":[{"ename":"NameError","evalue":"name 'st' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3-4040760258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get the API keys from Streamlit secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mOPENAI_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mGOOGLE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecrets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GEMINI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"]}],"source":["# ============================================\n","# ðŸ”‘ API Keys\n","# ============================================\n","# Get the API keys from Streamlit secrets\n","OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n","GOOGLE_API_KEY = st.secrets[\"GEMINI_API_KEY\"]\n","\n","# Initialize OpenAI client (if still needed for other parts of the script)\n","client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","\n","# Configure Gemini API\n","genai.configure(api_key=GOOGLE_API_KEY)\n","# Initialize the Gemini model\n","gemini_model = genai.GenerativeModel('gemini-pro') # Or another suitable Gemini model"]},{"cell_type":"markdown","metadata":{"id":"c0e2d7af"},"source":["**Reasoning**:\n","The previous command failed because the code was executed in the notebook environment where `st` (Streamlit) is not defined. I need to write the code to the `app.py` file using `%%writefile -a` to append it, and then run the `app.py` file itself to test it, or proceed with adding the rest of the code before testing. Since I'm building the `app.py` file incrementally, I will continue appending the code.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":188,"status":"ok","timestamp":1751225362266,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"WOn84th_KmTv","outputId":"39de45cc-7cc9-479d-8a41-70f4c026e3ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# ðŸ”‘ API Keys\n","# ============================================\n","# Get the API keys from Streamlit secrets\n","OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n","GOOGLE_API_KEY = st.secrets[\"GEMINI_API_KEY\"]\n","\n","# Initialize OpenAI client (if still needed for other parts of the script)\n","client = openai.OpenAI(api_key=OPENAI_API_KEY)\n","\n","# Configure Gemini API\n","genai.configure(api_key=GOOGLE_API_KEY)\n","# Initialize the Gemini model\n","gemini_model = genai.GenerativeModel('gemini-pro') # Or another suitable Gemini model"]},{"cell_type":"markdown","metadata":{"id":"525c30a2"},"source":["**Reasoning**:\n","Now that the API key handling is added to `app.py`, I need to add the data loading and initial processing logic from the notebook to the `app.py` file. This includes the file upload and the cleaning and parsing of the 'Premium' and 'Trade Spread' columns.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1751225372094,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"f03a3f45","outputId":"0aa06ce7-330c-4353-928f-58901117c482"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# ðŸ“ File Uploader and Data Loading\n","# ============================================\n","st.title(\"OMENReport Generator\")\n","\n","uploaded_file = st.file_uploader(\"Upload the SpyderTrades CSV or Excel file\", type=[\"csv\", \"xls\", \"xlsx\"])\n","\n","if uploaded_file is not None:\n","    try:\n","        # Read the file into a DataFrame\n","        if uploaded_file.name.endswith('.csv'):\n","            df = pd.read_csv(uploaded_file)\n","        elif uploaded_file.name.endswith(('.xls', '.xlsx')):\n","            df = pd.read_excel(uploaded_file)\n","        else:\n","            st.error(\"Unsupported file type.\")\n","            df = pd.DataFrame() # Create empty DataFrame if file type is unsupported\n","\n","        if not df.empty:\n","            # Clean column names by stripping leading/trailing spaces\n","            df.columns = df.columns.str.strip()\n","\n","            st.success(\"âœ… File uploaded and processed successfully.\")\n","            st.write(\"Original DataFrame Head:\")\n","            st.dataframe(df.head())\n","\n","            # ============================================\n","            # âš™ï¸ Process Data\n","            # ============================================\n","            def parse_premium(val):\n","                    try:\n","                        return float(str(val).replace('$', '').replace(',', '').replace('k', 'e3').replace('m', 'e6'))\n","                    except:\n","                        return 0\n","\n","            df['PremiumValue'] = df['Premium'].apply(parse_premium)\n","            st.write(\"âœ… Premium column parsed\")\n","\n","            # Parse sentiment from trade spread\n","            def get_sentiment(spread):\n","                if pd.isna(spread):\n","                    return 'Neutral'\n","                spread = str(spread).lower()\n","                if 'above ask' in spread:\n","                    return 'Aggressive Bullish'\n","                if 'ask' in spread:\n","                    return 'Bullish'\n","                if 'bidish' in spread:\n","                    return 'Bearish'\n","                if 'at bid' in spread:\n","                    return 'Aggressive Bearish'\n","                return 'Neutral'\n","\n","            df['Sentiment'] = df['Trade Spread'].apply(get_sentiment)\n","            st.write(\"âœ… Sentiment assigned\")\n","\n","            # Stealth indicator\n","            df['Stealth'] = df['Alerts'].apply(lambda x: 'âœ… High Stealth' if pd.notna(x) else 'âŒ None')\n","\n","            # Trade Type\n","            df['Trade Type'] = df['Flags'].fillna('Unknown')\n","\n","            # Strike/Expiry label\n","            df['StrikeExpiry'] = df['Strike'].astype(str) + ' ' + df['Call/Put'].astype(str) + ' â€“ ' + df['Expiration Date'].astype(str)\n","\n","            # Rename the 'Symbol' column to 'Ticker' for consistency and merging later\n","            df = df.rename(columns={'Symbol': 'Ticker'})\n","\n","            st.write(\"DataFrame Head after initial processing:\")\n","            st.dataframe(df.head())\n","\n","            # Store the processed DataFrame in session state\n","            st.session_state['processed_df'] = df\n","\n","    except Exception as e:\n","        st.error(f\"An error occurred during file processing: {e}\")\n","else:\n","    st.info(\"Please upload a file to get started.\")"]},{"cell_type":"markdown","metadata":{"id":"55058996"},"source":["**Reasoning**:\n","The subtask is to add the data summarization logic to the Streamlit app. This involves grouping the DataFrame by Ticker and calculating summary statistics, identifying the max premium trade for each ticker, merging this information, and adding dummy Market Cap tags.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1751225381590,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"ba0e5147","outputId":"554f846a-42a4-4a8f-f28b-5e493d63afac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# ðŸ“Š Summary Table\n","# ============================================\n","if 'processed_df' in st.session_state and not st.session_state['processed_df'].empty:\n","    df = st.session_state['processed_df'].copy() # Get the processed DataFrame\n","\n","    summary = df.groupby('Ticker').agg({\n","        'PremiumValue': ['sum', 'max', 'count']\n","    }).reset_index()\n","\n","    summary.columns = ['Ticker', 'Total Premium', 'Max Premium', 'Trade Count']\n","\n","    # Pull info for max premium trade\n","    # Ensure the index exists before using idxmax\n","    max_premium_indices = df.groupby('Ticker')['PremiumValue'].idxmax()\n","    max_trades_list = []\n","    for ticker, idx in max_premium_indices.items():\n","        # Check if idx is a valid index in df\n","        if idx in df.index:\n","            max_trades_list.append(df.loc[idx][\n","                ['Ticker', 'Trade Type', 'StrikeExpiry', 'Sentiment', 'Stealth']\n","            ])\n","    if max_trades_list:\n","        max_trades = pd.DataFrame(max_trades_list)\n","    else:\n","        max_trades = pd.DataFrame(columns=['Ticker', 'Trade Type', 'StrikeExpiry', 'Sentiment', 'Stealth'])\n","\n","\n","    summary = summary.merge(max_trades, on='Ticker', how='left') # Merge on Ticker\n","\n","    # Dummy Market Cap tags (adjust as needed)\n","    summary['Market Cap'] = 'Mid Cap'\n","    # Example small cap tickers - update as necessary\n","    small_cap_tickers = ['RKLB', 'SOUN', 'ACHR', 'NVTS'] # Example list\n","    summary.loc[summary['Ticker'].isin(small_cap_tickers), 'Market Cap'] = 'Small Cap'\n","\n","    st.write(\"âœ… Data summarized\")\n","    st.write(\"Summary DataFrame Head:\")\n","    st.dataframe(summary.head())\n","\n","    # Merge the 'Market Cap' column from the summary DataFrame into the main df DataFrame\n","    df = df.merge(summary[['Ticker', 'Market Cap']], on='Ticker', how='left')\n","\n","    # Store the updated DataFrame with Market Cap and the summary DataFrame in session state\n","    st.session_state['df_with_market_cap'] = df\n","    st.session_state['summary_df'] = summary\n"]},{"cell_type":"markdown","metadata":{"id":"f462acab"},"source":["**Reasoning**:\n","The subtask is to add the code that defines and implements the Ben Sturgil strategy criteria as new columns in the DataFrame.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1751225390774,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"79f6cb03","outputId":"1d725887-fb8d-4010-a0d1-9fb1e15a3735"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# âš™ï¸ Create Strategy Columns\n","# ============================================\n","if 'df_with_market_cap' in st.session_state and not st.session_state['df_with_market_cap'].empty:\n","    df = st.session_state['df_with_market_cap'].copy() # Get the DataFrame with Market Cap\n","\n","    # 1. Sweep Orders\n","    df['Sweep'] = df['Flags'].fillna('').apply(lambda x: 'Sweep' in x)\n","\n","    # 2. Above Ask\n","    df['Above Ask'] = df['Trade Spread'].fillna('').apply(lambda x: 'Above Ask' in x)\n","\n","    # 3. Volume > Open Interest\n","    # Clean and convert 'Trade Size' and 'Open Interest' to numeric, handling errors and NaNs\n","    def clean_numeric_column(col):\n","        col = col.astype(str).str.replace(',', '', regex=False).replace('nan', '0', regex=False)\n","        return pd.to_numeric(col, errors='coerce').fillna(0)\n","\n","    df['Trade Size_numeric'] = clean_numeric_column(df['Trade Size'])\n","    df['Open Interest_numeric'] = clean_numeric_column(df['Open Interest'])\n","\n","    df['Vol > OI'] = df['Trade Size_numeric'] > df['Open Interest_numeric']\n","\n","    # 4. Repeater Orders\n","    df['Repeater'] = df['Alerts'].fillna('').apply(lambda x: 'Repeater' in x)\n","\n","    # 5. Odd Lots\n","    # Simple check: not a multiple of 100 for Trade Size > 0\n","    df['Odd Lot'] = df['Trade Size_numeric'].apply(lambda x: x > 0 and x % 100 != 0)\n","\n","    # 6. Short-Dated Contracts\n","    # Convert 'Expiration Date' to datetime, handling errors\n","    df['Expiration Date_datetime'] = pd.to_datetime(df['Expiration Date'], errors='coerce')\n","\n","    # Define short-dated as less than 30 days from the current date\n","    current_date = pd.Timestamp.now()\n","    df['Short Dated'] = (df['Expiration Date_datetime'] - current_date).dt.days < 30\n","    df['Short Dated'] = df['Short Dated'].fillna(False) # Handle cases where Expiration Date was invalid\n","\n","    st.write(\"âœ… Strategy columns created\")\n","    st.write(\"DataFrame Head with Strategy Columns:\")\n","    st.dataframe(df[['Ticker', 'Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']].head())\n","\n","    # Store the DataFrame with strategy columns in session state\n","    st.session_state['df_with_strategies'] = df"]},{"cell_type":"markdown","metadata":{"id":"10f3b271"},"source":["**Reasoning**:\n","The subtask is to define and implement the scoring system based on Sentiment, Stealth, and Unusual Option Activity. This involves calculating a score for each trade based on these factors and adding it as a new column to the DataFrame.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1751225400510,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"fdefb6d1","outputId":"5d2d1d1e-0385-485e-be9a-02c72f0bf52e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# ðŸ“Š Define Unusual Option Activity Criteria and Implement Identification\n","# ============================================\n","if 'df_with_strategies' in st.session_state and not st.session_state['df_with_strategies'].empty:\n","    df = st.session_state['df_with_strategies'].copy() # Get the DataFrame with strategies\n","    summary = st.session_state['summary_df'].copy() # Get the summary DataFrame\n","\n","    # 1. Define a threshold for \"Large Premium\" (using the 95th percentile of 'PremiumValue')\n","    large_premium_threshold = df['PremiumValue'].quantile(0.95)\n","    st.write(f\"\\nLarge Premium Threshold (95th percentile): ${large_premium_threshold:,.2f}\")\n","\n","    # 2. Create the 'IsUnusual' column based on the three criteria\n","    df['IsUnusual'] = (\n","        (df['PremiumValue'] > large_premium_threshold) | # Criterion 1: Large Premium\n","        (df['Vol > OI']) | # Criterion 2: Volume > Open Interest (already calculated)\n","        ((df['Sweep'] | df['Repeater']) & df['Above Ask']) # Criterion 3: Aggressive Execution with Strategy Flags\n","    )\n","    st.write(f\"Number of trades flagged as unusual: {df['IsUnusual'].sum()}\")\n","    st.write(\"DataFrame Head with IsUnusual Column:\")\n","    st.dataframe(df[['Ticker', 'PremiumValue', 'Vol > OI', 'Sweep', 'Repeater', 'Above Ask', 'IsUnusual']].head())\n","\n","\n","    # ============================================\n","    # ðŸ“Š Define and Implement Scoring System\n","    # ============================================\n","    def calculate_score(row):\n","        \"\"\"Calculates a trade score based on sentiment, stealth, and unusual activity.\"\"\"\n","        score = 0\n","\n","        # Score based on Sentiment (example weighting)\n","        # Using the Sentiment from the main df, not the summary, for scoring individual trades\n","        if row['Sentiment'] == 'Aggressive Bullish' or row['Sentiment'] == 'Aggressive Bearish':\n","            score += 5\n","        elif row['Sentiment'] == 'Bullish' or row['Sentiment'] == 'Bearish':\n","            score += 3\n","        else: # Neutral\n","            score += 1\n","\n","        # Score based on Stealth\n","        if row['Stealth'] == 'âœ… High Stealth':\n","            score += 4\n","        else: # âŒ None\n","            score += 1\n","\n","        # Score based on Unusual Activity\n","        if row['IsUnusual']:\n","            score += 5\n","        else:\n","            score += 1 # Even non-unusual trades get a base score\n","\n","        return score\n","\n","    # Apply the function to create the 'Score' column\n","    df['Score'] = df.apply(calculate_score, axis=1)\n","\n","    st.write(\"âœ… Trade scores calculated\")\n","    st.write(\"DataFrame Head with Score Column:\")\n","    st.dataframe(df[['Ticker', 'Sentiment', 'Stealth', 'IsUnusual', 'Score']].head())\n","\n","    # Store the DataFrame with scores in session state\n","    st.session_state['df_with_scores'] = df"]},{"cell_type":"markdown","metadata":{"id":"4c58bd2d"},"source":["**Reasoning**:\n","The subtask is to filter the top trades based on the calculated scores and premium, for both overall and small cap categories. This involves sorting the DataFrame and selecting the top N rows from the sorted DataFrame and the filtered small-cap DataFrame.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67,"status":"ok","timestamp":1751225410697,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"cc928db1","outputId":"259ed5b3-dedc-47f2-f3fa-5cab72089abf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# ðŸ”¥ Filter Top Trades (Using New Scoring)\n","# ============================================\n","if 'df_with_scores' in st.session_state and not st.session_state['df_with_scores'].empty:\n","    df = st.session_state['df_with_scores'].copy() # Get the DataFrame with scores\n","    summary = st.session_state['summary_df'].copy() # Get the summary DataFrame\n","\n","\n","    # Sort the DataFrame by 'Score' (descending) and 'PremiumValue' (descending)\n","    df_sorted = df.sort_values(by=['Score', 'PremiumValue'], ascending=[False, False]).copy() # Use .copy() to avoid SettingWithCopyWarning\n","\n","    # Select the top 3 overall trades\n","    top3_overall_scored = df_sorted.head(3).copy() # Use .copy()\n","\n","    # Filter for Small Cap trades and select the top 3\n","    small_cap_df_sorted = df_sorted[df_sorted['Market Cap'].str.lower() == 'small cap'].copy() # Use .copy()\n","    top3_small_cap_scored = small_cap_df_sorted.head(3).copy() # Use .copy()\n","\n","    # Merge relevant columns from the summary DataFrame into top3_overall_scored\n","    top3_overall_scored = top3_overall_scored.merge(\n","        summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","        on='Ticker',\n","        how='left',\n","        suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n","    )\n","\n","    # Merge relevant columns from the summary DataFrame into top3_small_cap_scored\n","    top3_small_cap_scored = top3_small_cap_scored.merge(\n","        summary[['Ticker', 'Total Premium', 'Max Premium', 'Trade Count', 'Sentiment', 'Stealth']],\n","        on='Ticker',\n","        how='left',\n","        suffixes=('_scored', '_summary') # Add suffixes to distinguish columns if needed\n","    )\n","\n","\n","    st.write(\"âœ… Top 3 overall and small cap trades filtered (using new scoring)\")\n","    st.write(\"Top 3 Overall Scored Trades:\")\n","    st.dataframe(top3_overall_scored[['Ticker', 'Score', 'PremiumValue', 'Sentiment_summary', 'Stealth_summary', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count']])\n","    st.write(\"Top 3 Small Cap Scored Trades:\")\n","    st.dataframe(top3_small_cap_scored[['Ticker', 'Score', 'PremiumValue', 'Sentiment_summary', 'Stealth_summary', 'Market Cap', 'Total Premium', 'Max Premium', 'Trade Count']])\n","\n","\n","    # Store the top trades in session state\n","    st.session_state['top3_overall_scored'] = top3_overall_scored\n","    st.session_state['top3_small_cap_scored'] = top3_small_cap_scored"]},{"cell_type":"markdown","metadata":{"id":"6a2fe606"},"source":["## Process data and generate report\n","\n","### Subtask:\n","Adapt the existing data processing and report generation logic to work within the Streamlit app's flow.\n"]},{"cell_type":"markdown","metadata":{"id":"35babbca"},"source":["**Reasoning**:\n","Define the AI summary function, the report formatting function, and then within the file upload block, filter the top trades, add a button, and when clicked, generate the report content and store it in session state.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1751225430936,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"0ee4e2ed","outputId":"17da9ae6-4bfb-470d-85e2-bac71f131e70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# ðŸ§  AI Summary Function (Using OpenAI and Gemini)\n","# ============================================\n","def ai_summary(ticker, premium, trade_type, strike_expiry, sentiment, stealth):\n","    prompt = f\"\"\"\n","Write a short professional summary of the following options trade:\n","\n","Ticker: {ticker}\n","Trade Type: {trade_type}\n","Premium: ${premium:,.0f}\n","Strike/Expiry: {strike_expiry}\n","Sentiment: {sentiment}\n","Stealth Indicator: {stealth}\n","\n","Summarize the intent behind this flow in the style of an institutional options flow report.\n","\"\"\"\n","    try:\n","        # Prioritize Gemini if available and configured\n","        if 'gemini_model' in globals() and gemini_model:\n","            response = gemini_model.generate_content(prompt)\n","            return response.text\n","        # Fallback to OpenAI if Gemini is not available\n","        elif 'client' in globals() and client:\n","             response = client.chat.completions.create(\n","              model=\"gpt-4\",  # You can choose a different OpenAI model if preferred\n","              messages=[\n","                {\"role\": \"system\", \"content\": \"You are a financial analyst specializing in options trading.\"},\n","                {\"role\": \"user\", \"content\": prompt}\n","              ]\n","            )\n","             return response.choices[0].message.content\n","        else:\n","            return \"AI models not initialized.\"\n","\n","    except Exception as e:\n","        return f\"Error generating summary with AI: {e}\"\n","\n","\n","# ============================================\n","# ðŸ“ OMENReport Template With AI Summaries (TXT Format)\n","# ============================================\n","# Define a function to format the scored trade data and AI summaries for TXT\n","def format_scored_omen_template_txt(df, title, strategy_columns):\n","    \"\"\"Formats scored trade data and AI summaries into a string for the TXT report.\"\"\"\n","    report = f\"\\nðŸš€ OMENReport â€“ {title}\\n\\n\"\n","    report += f\"ðŸ“… Date: {datetime.now().strftime('%B %d, %Y')}\\n\\n\"\n","\n","    for _, row in df.iterrows():\n","        report += \"==========================================\\n\"\n","        report += f\"ðŸ”¶ Ticker: {row['Ticker']}\\n\"\n","        report += f\"- Market Cap: {row['Market Cap']}\\n\"\n","        report += f\"- Score: {row['Score']}\\n\" # Include the score\n","        report += f\"- Trade Type: {row['Trade Type']}\\n\"\n","        report += f\"- Strike/Expiry: {row['StrikeExpiry']}\\n\"\n","        report += f\"- Premium Size (Max Trade): ${row['Max Premium']:,.0f}\\n\" # Use Max Premium from summary merge\n","        report += f\"- Total Premium: ${row['Total Premium']:,.0f}\\n\" # Use Total Premium from summary merge\n","        report += f\"- Trade Count: {int(row['Trade Count'])}\\n\" # Use Trade Count from summary merge\n","        report += f\"- Sentiment: {row['Sentiment_summary']}\\n\" # Use Sentiment from summary merge\n","        report += f\"- Stealth Indicator: {row['Stealth_summary']}\\n\" # Use Stealth from summary merge\n","        report += \"\\n\"\n","\n","        # Add strategy criteria details\n","        report += \"Strategy Criteria Met:\\n\"\n","        for col in strategy_columns:\n","            # Ensure the column exists and is boolean before checking\n","            if col in row and isinstance(row[col], (bool, np.bool_)):\n","                 status = \"âœ… Yes\" if row[col] else \"âŒ No\"\n","                 report += f\"  - {col}: {status}\\n\"\n","        report += \"\\n\"\n","\n","\n","        report += \"ðŸ§  AI Summary:\\n\"\n","        # Generate AI summary using the AI-powered function\n","        try:\n","            ai_text = ai_summary(\n","                ticker=row['Ticker'],\n","                premium=row['Max Premium'],\n","                trade_type=row['Trade Type'],\n","                strike_expiry=row['StrikeExpiry'],\n","                sentiment=row['Sentiment_summary'],\n","                stealth=row['Stealth_summary']\n","            )\n","            report += f\"{ai_text}\\n\"\n","        except Exception as e:\n","             report += f\"Error generating AI summary: {e}\\n\"\n","\n","        report += \"==========================================\\n\\n\"\n","\n","    return report\n","\n","\n","# ============================================\n","# ðŸš€ Generate and Display Report\n","# ============================================\n","# Check if the necessary data is in session state\n","if 'top3_overall_scored' in st.session_state and 'top3_small_cap_scored' in st.session_state:\n","    top3_overall_scored = st.session_state['top3_overall_scored'].copy()\n","    top3_small_cap_scored = st.session_state['top3_small_cap_scored'].copy()\n","\n","    # Add a button to trigger report generation\n","    if st.button(\"Run Scan and Generate Report\"):\n","        st.info(\"Generating report... This may take a moment.\")\n","\n","        # Define the strategy columns used for criteria\n","        strategy_columns = ['Sweep', 'Above Ask', 'Vol > OI', 'Repeater', 'Odd Lot', 'Short Dated']\n","\n","        # Call the formatting function for the top 3 overall scored trades\n","        top3_overall_report = format_scored_omen_template_txt(top3_overall_scored, \"Top 3 Overall Scored Trades\", strategy_columns)\n","\n","        # Call the formatting function for the top 3 small cap scored trades\n","        top3_small_cap_report = format_scored_omen_template_txt(top3_small_cap_scored, \"Top 3 Small Cap Scored Trades\", strategy_columns)\n","\n","        # Concatenate the reports\n","        full_report = top3_overall_report + top3_small_cap_report\n","\n","        # Display the report in the Streamlit app\n","        st.subheader(\"Generated OMENReport:\")\n","        st.text(full_report)\n","\n","        # Store the full report in session state for download\n","        st.session_state['full_report'] = full_report\n","\n","        st.success(\"âœ… Report generated successfully.\")\n"]},{"cell_type":"markdown","metadata":{"id":"c7c7bbed"},"source":["**Reasoning**:\n","The report content is now stored in Streamlit's session state. The next step is to provide a download button for the user to save the report as a .txt file.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":224,"status":"ok","timestamp":1751225440123,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"3135be23","outputId":"4957eb39-280b-4316-81c6-36833608e925"},"outputs":[{"name":"stdout","output_type":"stream","text":["Appending to app.py\n"]}],"source":["%%writefile -a app.py\n","\n","# ============================================\n","# â¬‡ï¸ Download Report\n","# ============================================\n","# Provide a download button if the full report is in session state\n","if 'full_report' in st.session_state and st.session_state['full_report']:\n","    report_filename = \"OMENReport_Scored_AI.txt\"\n","    st.download_button(\n","        label=\"Download Report\",\n","        data=st.session_state['full_report'],\n","        file_name=report_filename,\n","        mime=\"text/plain\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"72c9b7b3"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","*   A `requirements.txt` file was successfully generated, listing `pandas`, `matplotlib`, `openpyxl`, `fpdf2`, `openai`, `google-generativeai`, and `streamlit` as necessary libraries.\n","*   The Streamlit application (`app.py`) structure was created, including imports, API key handling using `st.secrets`, a file uploader for CSV or Excel files, and initial data loading and processing logic.\n","*   The data processing steps from the original notebook were adapted and included in `app.py`, covering premium parsing, sentiment assignment, stealth indication, trade type identification, strike/expiry labeling, and column renaming.\n","*   Data summarization logic was implemented to group trades by ticker and calculate total premium, max premium, and trade count. Details of the max premium trade were merged, and dummy market cap tags were added.\n","*   Strategy-specific columns (`Sweep`, `Above Ask`, `Vol > OI`, `Repeater`, `Odd Lot`, `Short Dated`) were created based on defined criteria, including numeric conversion and date calculations.\n","*   An \"unusual\" trade criterion was defined based on large premium (95th percentile), Volume > Open Interest, and aggressive execution with strategy flags.\n","*   A scoring system was implemented to assign a score to each trade based on Sentiment, Stealth, and whether the trade was flagged as \"unusual\".\n","*   The DataFrame was sorted by the calculated score and premium value to filter the top 3 overall trades and the top 3 small-cap trades.\n","*   An AI summary function (`ai_summary`) was created to generate summaries for individual trades using configured OpenAI or Gemini models.\n","*   A function (`format_scored_omen_template_txt`) was defined to format the scored trade data and AI summaries into a structured text report.\n","*   A Streamlit button (\"Run Scan and Generate Report\") was added to trigger the report generation process, calling the formatting function for the top trades.\n","*   The generated report was stored in Streamlit's session state and displayed in the app using `st.text()`.\n","*   A download button was added to allow users to export the generated report as a `.txt` file.\n","\n","### Insights or Next Steps\n","\n","*   The application successfully integrates file uploading, data processing, analysis (including unusual activity and scoring), AI-powered summaries, and report generation within a Streamlit framework.\n","*   The next step is to ensure robust error handling for all data processing steps and API calls and to potentially enhance the AI prompts for more detailed or customized summaries.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bff5de49","outputId":"6ecedde2-4c82-485c-b4f7-a23d8ecad95a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.27.60.47:8501\u001b[0m\n","\u001b[0m\n"]}],"source":["!streamlit run SpyderStream.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16344,"status":"ok","timestamp":1751225899833,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"},"user_tz":420},"id":"c57afe09","outputId":"b497a640-6453-47bf-a1b6-5b746c08aa96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.10.0)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.1.5)\n","Collecting fpdf2 (from -r requirements.txt (line 4))\n","  Downloading fpdf2-2.8.3-py2.py3-none-any.whl.metadata (69 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.91.0)\n","Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.8.5)\n","Collecting streamlit (from -r requirements.txt (line 7))\n","  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.2.3)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->-r requirements.txt (line 3)) (2.0.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from fpdf2->-r requirements.txt (line 4)) (0.7.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 5)) (4.14.0)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirements.txt (line 6)) (0.6.15)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirements.txt (line 6)) (2.25.1)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirements.txt (line 6)) (2.173.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirements.txt (line 6)) (2.38.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai->-r requirements.txt (line 6)) (5.29.5)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 6)) (1.26.1)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (8.2.1)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (0.10.2)\n","Collecting watchdog<7,>=2.1.5 (from streamlit->-r requirements.txt (line 7))\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 7))\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 7)) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (4.24.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (1.44.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (3.10)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7)) (4.0.12)\n","Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai->-r requirements.txt (line 6)) (1.70.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 6)) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 6)) (4.9.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5)) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5)) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 5)) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5)) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5)) (0.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 7)) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 7)) (2.4.0)\n","Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 6)) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 6)) (4.2.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 7)) (5.0.2)\n","Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 6)) (1.73.0)\n","Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 6)) (1.71.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 7)) (0.25.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 6)) (0.6.1)\n","Downloading fpdf2-2.8.3-py2.py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m245.7/245.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, fpdf2, pydeck, streamlit\n","Successfully installed fpdf2-2.8.3 pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f60077ab"},"outputs":[],"source":["!lsof -i :8501"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"276ed7d1"},"outputs":[],"source":["!lsof -i :8501"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5f6480b7","executionInfo":{"status":"ok","timestamp":1751246462475,"user_tz":420,"elapsed":118,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"}},"outputId":"80a64081-3a93-47a3-9287-5630f14d4458"},"source":["!streamlit run SpyderStream.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: streamlit: command not found\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3911a775","executionInfo":{"status":"ok","timestamp":1751246513936,"user_tz":420,"elapsed":12819,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"}},"outputId":"a6f8d096-a8fb-40b3-a918-e921c1d2742b"},"source":["!pip install streamlit"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8c12bd20","outputId":"30916c3a-933d-43ff-c426-ce2f22a9c3b6"},"source":["!streamlit run pyderStream.pyS"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.185.59.129:8501\u001b[0m\n","\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6b2baaf","executionInfo":{"status":"ok","timestamp":1751246567602,"user_tz":420,"elapsed":114,"user":{"displayName":"Erich Sweaney","userId":"08739710665369529309"}},"outputId":"0c07de50-11a3-4fb9-8a5a-4fc5fc4ec7b4"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}]},{"cell_type":"code","metadata":{"id":"f552d57a"},"source":["!pkill streamlit"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["097970d4"],"provenance":[],"authorship_tag":"ABX9TyO/futBdOJlwpnpcWrsvU6a"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}